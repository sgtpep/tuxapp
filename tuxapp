#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import absolute_import, print_function, unicode_literals

import functools
import glob
import hashlib
import os
import platform
import re
import stat
import subprocess
import sys
import textwrap
import time
import zipfile

__version__ = '1.0.0'

def check(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message:
        assert result, built_message
      return result
    return wrapper
  return decorator

def check_process_exceptions(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    try:
      return function(*args, **kwargs)
    except KeyboardInterrupt:
      print(file=sys.stderr)
      raise AssertionError
    except subprocess.CalledProcessError as exception:
      raise AssertionError('Command exited with code {}: {}'.format(exception.returncode, exception.cmd if isinstance(exception.cmd, type('')) else join_arguments(exception.cmd).replace('\\\n', '').strip()))
  return wrapper

def do(action):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      action(*args, result=result, **kwargs)
      return result
    return wrapper
  return decorator

def handle_exceptions(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    try:
      result = function(*args, **kwargs)
      if not result:
        sys.exit(1)
    except AssertionError as exception:
      if exception.args:
        print(exception.args[0], file=sys.stderr)
      sys.exit(1)
    except KeyboardInterrupt:
      print(file=sys.stderr)
      sys.exit(130)
  return wrapper

def lock_app(function):
  @functools.wraps(function)
  def wrapper(app, *args, **kwargs):
    if read_file(get_app_lock_path(app)) == os.getpid():
      return function(app, *args, **kwargs)
    else:
      previous_pid = None
      while True:
        pid = read_file(get_app_lock_path(app))
        if pid and os.path.isdir(os.path.join('/proc', pid)):
          if pid != previous_pid and not is_silent():
            previous_pid = pid
            print('Waiting for the process {}'.format(pid), file=sys.stderr)
          time.sleep(1)
        else:
          break
      try:
        write_file(get_app_lock_path(app), str(os.getpid()))
        return function(app, *args, **kwargs)
      finally:
        remove_file_ascending(get_app_lock_path(app))
  return wrapper

def log(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      built_message = build_decorator_message(message, *args, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return function(*args, **kwargs)
    return wrapper
  return decorator

def log_after(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      built_message = build_decorator_message(message, *args, **kwargs)
      result = function(*args, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return result
    return wrapper
  return decorator

def log_result(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return result
    return wrapper
  return decorator

def memoize(function):
  import collections
  cache = collections.OrderedDict()
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    key = '{}{}'.format(args, kwargs)
    if key not in cache:
      cache[key] = function(*args, **kwargs)
      if len(cache) > get_memoized_size():
        cache.popitem(False)
    return cache[key]
  if not hasattr(wrapper, '__wrapped__'):
    wrapper.__wrapped__ = function
  wrapper.remove = lambda *args, **kwargs: remove_memoized_cache(cache, *args, **kwargs)
  return wrapper

def memoize_temporarily(function):
  import collections
  cache = collections.OrderedDict()
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    key = '{}{}'.format(args, kwargs)
    if key not in cache or cache[key][1] < time.time() - get_memoized_time():
      cache[key] = function(*args, **kwargs), time.time()
      if len(cache) > get_memoized_size():
        cache.popitem(False)
    return cache[key][0]
  if not hasattr(wrapper, '__wrapped__'):
    wrapper.__wrapped__ = function
  wrapper.remove = lambda *args, **kwargs: remove_memoized_cache(cache, *args, **kwargs)
  return wrapper

def output(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message and not is_silent():
        print(built_message)
      return result
    return wrapper
  return decorator

def silence(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    if is_silent():
      return function(*args, **kwargs)
    else:
      silence.is_silent = True
      result = function(*args, **kwargs)
      del silence.is_silent
      return result
  return wrapper

def uncheck(default=None):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      try:
        return function(*args, **kwargs)
      except AssertionError:
        return default
    return wrapper
  return decorator

@check_process_exceptions
def call_process(arguments):
  subprocess.check_call(arguments, shell=isinstance(arguments, type('')))
  return True

def change_file_mode(path, get_mode):
  os.chmod(path, get_mode(os.stat(path).st_mode))
  return path

def check_app_firejail(app):
  if not is_silent():
    if is_existing_command('firejail'):
      if 'WAYLAND_DISPLAY' not in os.environ and not re.search(r' --x11[ =]', ' {} {} '.format(query_appfile(app, 'firejail'), read_app_firejail_options(app))):
        print(get_firejail_message('x11'), file=sys.stderr)
      if read_app_firejail_options(app):
        print(get_firejail_message('options').format(read_app_firejail_options(app)), file=sys.stderr)
    else:
      print(get_firejail_message('missing'), file=sys.stderr)
  return True

def commit_app_data(app):
  connect_app_data(app).commit()
  return True

@memoize
def connect_app_data_memoized(app):
  import sqlite3
  connection = sqlite3.connect(make_file_directories(get_app_data_path(app)))
  connection.execute('CREATE TABLE IF NOT EXISTS items (key TEXT PRIMARY KEY, value TEXT)')
  return connection

def copy_directory(path, destination_path):
  import distutils.dir_util
  distutils.dir_util._path_created = {} # pylint: disable=protected-access
  distutils.dir_util.copy_tree(path, destination_path, update=True)
  return destination_path

def copy_file(path, destination_path):
  import shutil
  shutil.copyfile(path, make_file_directories(destination_path))
  return destination_path

def copy_file_content(file, destination_file, offset=0, size=None, chunk_size=65536):
  with file, destination_file:
    file.seek(offset)
    try:
      if size:
        try:
          import builtins
        except ImportError:
          import __builtin__ as builtins
        for _ in getattr(builtins, 'xrange', range)(size // chunk_size):
          destination_file.write(file.read(chunk_size))
        destination_file.write(file.read(size % chunk_size))
      else:
        import shutil
        shutil.copyfileobj(file, destination_file, chunk_size)
      return True
    except IOError:
      return False

def is_existing_command(command):
  import distutils.spawn
  return bool(distutils.spawn.find_executable(command))

def make_directories(path):
  if not os.path.isdir(path):
    os.makedirs(path)
  return path

@memoize
def parse_arguments(arguments=None):
  import argparse
  parser = argparse.ArgumentParser(description=get_description(), epilog=', '.join((get_license(), get_copyright(), build_github_url())))
  parser.add_argument('-a', '--all', action='store_true', help='list apps available for installation')
  parser.add_argument('-c', '--check', action='store_true', help='check installed apps for updates')
  parser.add_argument('-e', '--execute', action='store_true', help='execute an installed app')
  parser.add_argument('-l', '--list', action='store_true', help='list installed apps')
  parser.add_argument('-p', '--purge', action='store_true', help='purge cache')
  parser.add_argument('-r', '--remove', action='store_true', help='remove installed apps')
  parser.add_argument('-u', '--update', action='store_true', help='update installed apps')
  parser.add_argument('-v', '--version', action='version', version='{} {}'.format(get_name(), get_version()))
  parser.add_argument('arguments', help='an app name', metavar='app', nargs='*')
  parsed_arguments = parser.parse_args(arguments)
  return parsed_arguments

@memoize
@check(lambda path, *args, **kwargs: 'Failed to parse {}'.format(os.path.basename(path)))
def parse_package_data_header(path):
  import contextlib
  import mmap
  with open(path, 'rb') as file, contextlib.closing(mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ)) as map_file:
    start = map_file.find(b'data.tar.')
    end = map_file.find(b'`\n', start)
    if start != -1 and end != -1:
      filename, _, _, _, _, size = map_file[start:end].decode('utf-8').split()
      return {
        'extension': re.sub(r'\W.*$', '', filename.replace('data.tar.', '', 1)),
        'offset': end + 2,
        'size': int(size),
      }

def parse_url(url):
  try:
    from urllib.parse import urlsplit
  except ImportError:
    from urlparse import urlsplit
  return urlsplit(url)

@check_process_exceptions
def pipe_process_stdin(file, arguments, offset=0, size=None):
  process = subprocess.Popen(arguments, stdin=subprocess.PIPE)
  if copy_file_content(file, process.stdin, offset, size):
    return process.wait() == 0
  else:
    return False

def quote_argument(string):
  try:
    from shlex import quote
  except ImportError:
    from pipes import quote
  return quote(str(string))

def read_file(path, size=-1, is_binary=False):
  if os.path.isfile(path):
    import io
    with io.open(path, 'rb' if is_binary else 'r') as file:
      return file.read(size)
  else:
    return ''

@check_process_exceptions
def read_process_binary(arguments, is_stderr_redirected=False):
  return subprocess.check_output(arguments, shell=isinstance(arguments, type('')), stderr=subprocess.STDOUT if is_stderr_redirected else None)

@check_process_exceptions
def read_process_lines(arguments, is_stderr_redirected=False):
  process = subprocess.Popen(arguments, shell=isinstance(arguments, type('')), stderr=subprocess.STDOUT if is_stderr_redirected else None, stdout=subprocess.PIPE)
  for line in iter(process.stdout.readline, b''):
    yield line.decode('utf-8', 'replace').rstrip('\n')

def remove_directory(path):
  if os.path.isdir(path):
    import shutil
    shutil.rmtree(path)
  return True

def remove_empty_directories(path):
  try:
    os.removedirs(path)
  except OSError:
    pass
  return True

def remove_file(path):
  if os.path.isfile(path):
    os.remove(path)
  return True

def remove_memoized_cache(cache, *args, **kwargs):
  key = '{}{}'.format(args, kwargs)
  if key in cache:
    del cache[key]
  return True

def rename_file(path, destination_path):
  os.rename(path, make_file_directories(destination_path))
  return destination_path

def request_last_modified(url):
  import email.utils
  return time.mktime(email.utils.parsedate(search(r'(?<=\bLast-Modified: ).+$', request_url_headers(url), re.I | re.M)) or time.gmtime())

def split_command(command):
  try:
    import shlex
    return tuple(shlex.split(command))
  except ValueError:
    return ()

def symlink_file(path, target_path):
  if not os.path.islink(target_path) or os.readlink(target_path) != path:
    if os.path.islink(target_path):
      os.remove(target_path)
    os.symlink(path, make_file_directories(target_path))
  return target_path

def touch_file(path, timestamp=None):
  os.utime(path if os.path.isfile(path) else write_file(path), timestamp and (timestamp, timestamp))
  return path

@log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))
@check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))
def unpack_zip_file(path, output_path):
  try:
    with zipfile.ZipFile(path) as file:
      for info in file.infolist():
        file.extract(info.filename, make_directories(output_path))
        os.chmod(os.path.join(output_path, info.filename), info.external_attr >> 16)
      return output_path
  except Exception as exception: # pylint: disable=broad-except
    if exception.args:
      print(exception.args[0], file=sys.stderr)

def write_file(path, content='', is_append=False):
  import io
  with io.open(make_file_directories(path), 'a' if is_append else 'w') as file:
    file.write(content if isinstance(content, type('')) else content.decode('utf-8', 'replace'))
    return path

append_file = lambda path, content='': write_file(path, content, True)

backup_app_cache = lambda app: \
  rename_file(get_app_data_path(app), build_cached_app_package_data_path(app, max(query_app_package_list_update_time(app, url) for url in build_app_package_list_urls(app) if query_app_package_list_update_time(app, url)))) and \
  all(remove_file(path) for path in glob.iglob(build_cached_app_package_data_path(app, '*')) if os.path.getatime(path) < time.time() - 60 * 60 * 24 * 7) and \
  all(remove_file(path) if os.path.isfile(get_cached_file_path(path)) else rename_file(path, get_cached_file_path(path)) for path in glob.iglob(get_app_cached_file_path(app, '*.deb'))) and \
  all(remove_file(path) for path in glob.iglob(get_cached_file_path('*.deb')) if os.path.getatime(path) < time.time() - 60 * 60 * 24 * 30)

build_app_bsdtar_arguments = lambda app: \
  ('bsdtar',) \
    if is_existing_command('bsdtar') else \
  install_app_packages(app, ('libarchive-tools', 'liblzo2-2')) and \
  (('firejail', '--quiet', '--env={}'.format(build_app_library_variable(app))) if is_existing_command('firejail') else ('env', build_app_library_variable(app))) + \
  (get_app_root_binary_path(app, 'bsdtar'),)

build_app_distribution_download_path = lambda app, url: get_app_distribution_download_path(app, '{}-{}'.format(request_app_version(app), hash_md5(url)))

build_app_library_variable = lambda app: 'LD_LIBRARY_PATH={}'.format(':'.join(path for pattern in ('lib/*-linux-gnu', 'usr/lib/*-linux-gnu') for path in glob.iglob(os.path.join(get_app_root_path(app), pattern))))

build_app_package_list_download_path = lambda app, url: get_app_package_list_download_path(app, hash_md5(url))

build_app_package_list_urls = \
  check(lambda app, *args, **kwargs: 'Unknown package repository: {}'.format(query_appfile(app, 'package-repository')))(
    lambda app: \
      tuple(url.format(query_appfile(app, 'package-repository'), 'binary-{}/Packages.xz'.format(detect_debian_architecture())) for url in (
        (get_debian_mirror_url() + path for path in (
          'debian/dists/{}/main/{}',
          'debian-security/dists/{}/updates/main/{}',
        )) \
          if query_appfile(app, 'package-repository') == 'stretch' else \
        (get_ubuntu_mirror_url() + path for path in (
          'ubuntu/dists/{}/main/{}',
          'ubuntu/dists/{}/universe/{}',
          'ubuntu/dists/{}-security/main/{}',
        )) \
          if query_appfile(app, 'package-repository') == 'xenial' else \
        ()
      ))
  )

build_app_runner_relative_path = lambda app, path: re.sub(r'/\.$', '', os.path.join('${0%/*}', quote_argument(os.path.relpath(path, os.path.dirname(get_app_runner_path(app))))))

build_app_temp_download_path = lambda app, url: build_download_path(get_app_temp_downloads_path(app), url)

build_cached_app_package_data_path = lambda app, timestamp: get_cached_file_path('packages-{}-{}'.format(query_appfile(app, 'package-repository'), timestamp))

build_curl_request_arguments = lambda options, is_gzip=False: \
  ('curl', '-#Lf', '-H', 'Accept-Language: en', '-m', '10', '--retry', '2') + \
  (() if parse_url(options[-1]).netloc == 'downloads.sourceforge.net' else ('-A', get_user_agent())) + \
  (('-H', 'Accept-Encoding: gzip') if is_gzip else ()) + \
  options

build_data_key = lambda components: ':'.join(str(component) for component in components)

build_decorator_message = lambda string, *args, **kwargs: \
  string(*args, **kwargs) \
    if callable(string) else \
  string.format(*args, **kwargs)

build_desktop_entry_category = lambda category: \
  ('AudioVideo;' if category in ('audio', 'video') else '') + \
  '{};'.format(category.title())

build_download_path = lambda path, url: os.path.join(path, os.path.basename(parse_url(url).path))

build_github_api_url = lambda path: 'https://api.github.com/{}'.format(path)

build_github_raw_url = lambda path: 'https://raw.githubusercontent.com/{}/master/{}'.format(get_github_repository(), path)

build_github_url = lambda url='': 'https://github.com/{}{}'.format(get_github_repository(), url and '/{}'.format(url))

build_request_arguments = lambda curl_options=(), wget_options=(), is_gzip=False: \
  build_curl_request_arguments(curl_options, is_gzip) \
    if get_request_command() == 'curl' else \
  build_wget_request_arguments(wget_options, is_gzip)

build_wget_request_arguments = lambda options, is_gzip=False: \
  ('wget', '-T', '10', '-t', '3', '-nv', '--header', 'Accept-Language: en') + \
  (() if parse_url(options[-1]).netloc == 'downloads.sourceforge.net' else ('-U', get_user_agent())) + \
  (('--header', 'Accept-Encoding: gzip') if is_gzip else ()) + \
  options

check_app_installed = \
  check('{} is not installed')(
    lambda app: \
      is_app_installed(app) and \
      app
  )

check_app_updated = \
  log_after(lambda app, *args, **kwargs: not is_existing_command('firejail') and resolve_outdated_app_packages(app, query_appfile(app, 'packages')) and 'Warning: packages of {} are outdated'.format(app))(
  log_result(lambda app, *args, **kwargs: \
    '{} {} is up to date'.format(app, read_app_version(app)) \
      if kwargs['result'] else \
    '{} can be updated from {} to {}'.format(app, read_app_version(app), request_app_version(app))
  )(
    lambda app: is_app_updated(app)
  ))

check_apps_updated = \
  output(lambda *args, **kwargs: \
    'No updates' \
      if all(is_updated for app, is_updated in kwargs['result']) else \
    'Updates available: {}'.format(', '.join('{} {}'.format(app, request_app_version(app)) for app, is_updated in kwargs['result'] if not is_updated))
  )(
    lambda apps: tuple((app, check_app_updated(app)) for app in apps)
  )

connect_app_data = lambda app: \
  (os.path.isfile(get_app_data_path(app)) or connect_app_data_memoized.remove(app)) and \
  connect_app_data_memoized(app)

detect_architecture = \
  check(lambda *args, **kwargs: 'Unknown architecture: {}'.format(platform.machine()))(
    lambda: \
      {
        'i386': 'x86',
        'i686': 'x86',
        'ia64': 'x86-64',
        'x86_64': 'x86-64',
      }.get(platform.machine())
  )

detect_debian_architecture = \
  check(lambda *args, **kwargs: 'Unsupported architecture: {}'.format(detect_architecture()))(
    lambda: \
      {
        'x86': 'i386',
        'x86-64': 'amd64',
      }.get(detect_architecture())
  )

download_app_file = \
  log('Downloading {1}')(
  check('Failed to download {1}')(
    lambda app, url, path: \
      rename_file(build_app_temp_download_path(app, path), path) \
        if uncheck()(call_process)(build_request_arguments(
          (('-Ss',) if is_silent() else ()) + \
          ('-o', make_file_directories(build_app_temp_download_path(app, path)), url),
          (('-q',) if is_silent() else ('--show-progress',)) + \
          ('-O', make_file_directories(build_app_temp_download_path(app, path)), url),
        )) else \
      remove_file(build_app_temp_download_path(app, path)) and \
      None
  ))

download_app_files = \
  log(lambda app, urls, *args, **kwargs: urls and 'Downloading {}'.format(urls[0] if len(urls) == 1 else '{} files'.format(len(urls))))(
  check(lambda app, urls, *args, **kwargs: kwargs['result'] is None and 'Failed to download {}'.format(urls[0] if len(urls) == 1 else 'files'))(
    lambda app, urls, path: \
      () \
        if not urls else \
      all(remove_file(path) for url in urls if not os.path.isfile(build_app_temp_download_path(app, url)) for path in glob.iglob('{}.*'.format(build_app_temp_download_path(app, url)))) and \
      tuple(rename_file(build_app_temp_download_path(app, url), build_download_path(path, url)) for url in urls if os.path.isfile(build_app_temp_download_path(app, url))) \
        if (download_app_files_curl(app, urls, path) if get_request_command() == 'curl' else download_app_files_wget(app, urls, path)) else \
      all(remove_file(build_app_temp_download_path(app, url)) for url in urls) and \
      None
  ))

download_app_files_curl = lambda app, urls, path: \
  uncheck()(call_process)(build_curl_request_arguments(
    (('-Ss',) if is_silent() else ()) + \
    tuple(argument for url in urls for argument in ('-o', make_file_directories(build_app_temp_download_path(app, url)), url))
  )) and \
  all(os.path.isfile(build_app_temp_download_path(app, url)) for url in urls)

download_app_files_wget = lambda app, urls, path: \
  all(remove_file(build_app_temp_download_path(app, url)) for url in urls) and \
  uncheck()(call_process)(build_wget_request_arguments(
    (('-q',) if is_silent() else ('--show-progress',)) + \
    ('-P', make_directories(get_app_temp_downloads_path(app))) + \
    urls
  ))

download_app_packages = lambda app, packages: \
  tuple(copy_file(path, get_app_cached_file_path(app, path)) for path in (get_cached_file_path(parse_url(query_app_package_data(app, package, 'url')).path) for package in packages) if os.path.isfile(path)) + \
  download_missing_app_cache_files(app, set(query_app_package_data(app, package, 'url') for package in packages))

download_missing_app_cache_file = lambda app, url: download_missing_app_file(app, url, build_download_path(get_app_cache_path(app), url))

download_missing_app_cache_files = lambda app, urls: download_missing_app_files(app, urls, get_app_cache_path(app))

download_missing_app_file = lambda app, url, path: \
  path \
    if os.path.isfile(path) else \
  download_app_file(app, url, path)

download_missing_app_files = lambda app, urls, path: \
  tuple(path for path in (build_download_path(path, url) for url in urls) if os.path.isfile(path)) + \
  download_app_files(app, tuple(url for url in urls if not os.path.isfile(build_download_path(path, url))), path)

execute_app = lambda app, arguments=(): execute_process((get_app_runner_path(app),) + arguments)

execute_process = lambda arguments, environment=None: \
  os.execvpe(arguments[0], arguments, dict(os.environ, **environment)) \
    if environment else \
  os.execvp(arguments[0], arguments)

expand_package_group = lambda group: get_package_groups().get(group, (group,))

expand_package_groups = lambda packages: tuple(package for package in packages for package in expand_package_group(package))

extract_app = lambda string: os.path.basename(string)

extract_package_name = lambda path: os.path.basename(path).split('_', 1)[0]

extract_package_version = lambda path: path.split('_', 2)[1]

filter_app_download_url = lambda app, url: url.replace('{debian}', '{}debian/pool'.format(get_debian_mirror_url())).replace('{ubuntu}', '{}ubuntu/pool'.format(get_ubuntu_mirror_url())).replace('{version}', request_app_version(app))

get_app_cache_path = lambda app: os.path.join(get_app_path(app), 'cache')

get_app_cached_file_path = lambda app, path: os.path.join(get_app_cache_path(app), os.path.basename(path))

get_app_data_path = lambda app: get_app_cached_file_path(app, 'data')

get_app_desktop_entry_path = lambda app: os.path.join(os.environ.get('XDG_DATA_HOME', os.path.expanduser('~/.local/share')), 'applications/{}-{}.desktop'.format(get_name(), app))

get_app_distribution_binary_path = lambda app, filename: os.path.join(get_app_distribution_path(app), 'usr/bin', filename)

get_app_distribution_download_path = lambda app, suffix: get_app_cached_file_path(app, 'download-{}'.format(suffix))

get_app_distribution_path = lambda app: os.path.join(get_app_path(app), 'dist')

get_app_firejail_options_path = lambda app: os.path.join(get_app_path(app), 'firejail')

get_app_icon_path = lambda app: os.path.join(get_app_path(app), 'icon')

get_app_lock_path = lambda app: os.path.join(get_app_path(app), 'lock')

get_app_package_list_download_path = lambda app, suffix: get_app_cached_file_path(app, 'packages-{}'.format(suffix))

get_app_package_version_path = lambda app, package: os.path.join(get_app_root_path(app), 'var/lib/packages', package)

get_app_path = lambda app: os.path.join(os.path.expanduser('~/.{}'.format(get_name())), app)

get_app_root_binary_path = lambda app, filename: os.path.join(get_app_root_path(app), 'usr/bin', filename)

get_app_root_path = lambda app: os.path.join(get_app_path(app), 'root')

get_app_runner_path = lambda app: os.path.join(get_app_path(app), 'run')

get_app_temp_downloads_path = lambda app: os.path.join(get_app_cache_path(app), 'downloads')

get_app_version_path = lambda app: os.path.join(get_app_path(app), 'version')

get_appfile_path = lambda app: os.path.join(get_project_path(), 'apps', app)

get_cache_path = lambda: os.path.join(os.environ.get('XDG_CACHE_HOME', os.path.expanduser('~/.cache')), 'tuxapp')

get_cached_file_path = lambda path: os.path.join(get_cache_path(), os.path.basename(path))

get_copyright = lambda: '(c) {} Danil Semelenov'.format(get_copyright_range())

get_copyright_range = lambda: '{}{}'.format(get_copyright_year(), time.strftime('-%Y') if int(time.strftime('%Y')) > get_copyright_year() else '')

get_copyright_year = lambda: 2017

get_debian_mirror_url = lambda: 'https://cdn-aws.deb.debian.org/'

get_default_package_repository = lambda: 'stretch'

get_description = lambda: 'Downloads and installs the latest official releases of Linux® applications including dependencies without root permissions and allows to run them sandboxed.'

get_excluded_dependencies = lambda: \
  (
    'dpkg',
    'libc6',
  )

get_file_mtime = lambda path: \
  os.path.getmtime(path) \
    if os.path.isfile(path) else \
  0

get_firejail_blacklisted_paths = lambda: \
  (
    '~/.electron-cash',
    '~/.passwd-s3fs',
    '~/.s3cmd',
  )

get_firejail_message = lambda name: \
  {
    'missing': 'Warning: firejail is not installed on your system and will not be used to sandbox this app.{}'.format(get_package_install_command('firejail', ' Install it with the command: {}')),
    'options': 'Warning: firejail will run this app with custom options: {}',
    'x11': 'Warning: X11 sandboxing is not enabled for this app.', # 'To prevent it from reading any window contents and input events install this app with the --x11 option.',
  }[name]

get_github_repository = lambda: 'sgtpep/{}'.format(get_name())

get_installed_apps = \
  check('No apps are installed')(
    lambda: tuple(sorted(os.path.basename(os.path.dirname(path)) for path in glob.iglob(get_app_version_path('*'))))
  )

get_license = lambda: 'MIT License'

get_memoized_size = lambda: 128

get_memoized_time = lambda: 5 * 60

get_name = lambda: 'tuxapp'

get_package_exclusions = lambda package: \
  (
    '/etc',
    '/sbin',
    '/usr/sbin',
    '/var',
  ) + \
  (('/bin', '/usr/bin') if package.startswith('lib') and package != 'libarchive-tools' else ()) + \
  (() if package == 'libqt5webengine-data' else ('/usr/share',))

get_package_groups = lambda: \
  {
    'group-chromium': (
      'libasound2',
      'libgconf-2-4',
      'libgtk-3-0',
      'libnss3',
      'libxss1',
      'libxtst6',
    ),
    'group-electron': (
      'libasound2',
      'libgconf-2-4',
      'libgtk2.0-0',
      'libnss3',
      'libpulse0',
      'libxkbfile1',
      'libxss1',
      'libxtst6',
    ),
    'group-firefox': (
      'libdbus-glib-1-2',
      'libgtk-3-0',
      'libxt6',
    ),
    'group-opengl': (
      'libgl1-mesa-dri',
      'libgl1-mesa-glx',
    ),
  }

get_package_install_command = lambda package, message='{}': \
  message.format('sudo apt install {}'.format(package)) \
    if is_existing_command('apt') else \
  message.format('sudo apt-get install {}'.format(package)) \
    if is_existing_command('apt-get') else \
  message.format('sudo dnf install {}'.format(package)) \
    if is_existing_command('dnf') else \
  message.format('sudo pacman -S {}'.format(package)) \
    if is_existing_command('pacman') else \
  message.format('sudo yum install {}'.format(package)) \
    if is_existing_command('yum') else \
  message.format('sudo zypper install {}'.format(package)) \
    if is_existing_command('zypper') else \
  ''

get_project_path = lambda: os.path.dirname(os.path.realpath(__file__.rstrip('c')))

get_request_command = \
  check('Neither wget nor curl is installed')(
    lambda: \
      'wget' \
        if is_existing_command('wget') and not os.environ.get('TUXAPP_CURL') else \
      'curl' \
        if is_existing_command('curl') else \
      None
  )

get_request_gzip_command = lambda: 'gzip -df 2> /dev/null'

get_request_head_command = lambda: 'head -c 1000000 2> /dev/null'

get_tar_filter_option = \
  check('Unknown archive extension: {}')(
    lambda extension: \
      {
        'bz2': '-j',
        'gz': '-z',
        'lzma': '--lzma',
        'xz': '-J',
      }.get(extension)
  )

get_tar_progress_options = lambda: \
  () \
    if is_silent() else \
  ('--checkpoint=.250',)

get_ubuntu_mirror_url = lambda: 'http://archive.ubuntu.com/'

get_user_agent = lambda: 'Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'

get_version = lambda: __version__

hash_app_download_urls = lambda app: hash_md5(' '.join(query_appfile(app, 'download-urls')))

hash_md5 = lambda string: hashlib.md5(string.encode('utf-8', 'replace')).hexdigest()

install_app = \
  lock_app(
  log(lambda app, *args, **kwargs: \
    None \
      if is_app_updated(app) else \
    'Updating {} from {} to {}'.format(app, read_app_version(app), request_app_version(app)) \
      if is_app_installed(app) else \
    'Installing {} {}'.format(app, request_app_version(app))
  )(
  log_after(lambda app, *args, **kwargs: \
    '{} {} is up to date'.format(app, read_app_version(app)) \
      if is_app_updated(app) else \
    'Updated {} from {} to {}'.format(app, read_app_version(app), request_app_version(app)) \
      if is_app_installed(app) else \
    'Installed {} {}'.format(app, request_app_version(app))
  )(
    lambda app: \
      install_app_distribution(app) and \
      install_app_packages(app, query_appfile(app, 'packages')) and \
      install_app_runner(app) and \
      install_app_desktop_entry(app) and \
      get_app_path(app)
  )))

install_app_browser = lambda app: \
  write_bash_script(get_app_root_binary_path(app, 'browser'), r'''
  echo "$1" > "$TUXAPP_URLS"
  ''')

install_app_desktop_entry = \
  log_after(lambda app, *args, **kwargs: not os.path.isfile(get_app_desktop_entry_path(app)) and 'Added the menu item: {}'.format(query_appfile(app, 'name')))(
    lambda app: \
      write_file(get_app_desktop_entry_path(app), textwrap.dedent('''\
      [Desktop Entry]
      Categories={category}
      Comment={title}
      Exec={runner_path} %U
      Icon={icon_path}
      Name={name}
      TryExec={runner_path}
      Type=Application
      {appendix}''').format(
        appendix=query_appfile(app, 'desktop-entry'),
        category=build_desktop_entry_category(query_appfile(app, 'category')),
        icon_path=install_app_icon(app),
        name=query_appfile(app, 'name'),
        runner_path=get_app_runner_path(app),
        title=query_appfile(app, 'title'),
      ))
  )

install_app_distribution = lambda app: \
  get_app_distribution_path(app) \
    if is_app_updated(app) else \
  all(remove_file(path) for pattern in (os.path.join(get_app_distribution_path(app), '*'), get_app_distribution_binary_path(app, '*')) for path in glob.iglob(pattern) if is_file_executable(path)) and \
  all(unpack_app_distribution(app, path) for path in (download_missing_app_file(app, url, build_app_distribution_download_path(app, url)) for url in query_appfile(app, 'download-urls'))) and \
  all(remove_file(path) for path in glob.iglob(get_app_distribution_download_path(app, '*'))) and \
  write_app_version(app) and \
  get_app_distribution_path(app) \

install_app_icon = lambda app: \
  uncheck('')(download_app_file)(app, query_appfile(app, 'icon-url'), get_app_icon_path(app)) and \
  touch_file(get_app_icon_path(app)) \
    if is_file_newer(get_app_version_path(app), get_app_icon_path(app)) else \
  get_app_icon_path(app)

install_app_package_file = lambda app, path: \
  silence(unpack_package)(path, get_app_root_path(app), tuple('--exclude=.{}'.format(exclusion) for exclusion in get_package_exclusions(extract_package_name(path)))) and \
  patch_app_package(app, extract_package_name(path)) and \
  write_file(get_app_package_version_path(app, extract_package_name(path)), '{}\n'.format(extract_package_version(path))) and \
  extract_package_name(path)

install_app_package_files = \
  log(lambda app, paths, *args, **kwargs: paths and 'Installing packages: {}'.format(', '.join(extract_package_name(path) for path in paths)))(
    lambda app, paths: \
      all(install_app_package_file(app, path) for path in paths) and \
      True
  )

install_app_packages = \
  lambda app, packages: \
    (not packages or update_app_package_lists(app)) and \
    install_app_package_files(app, download_app_packages(app, resolve_outdated_app_packages(app, packages))) and \
    backup_app_cache(app)

install_app_runner = lambda app: \
  check_app_firejail(app) and \
  write_bash_script(get_app_runner_path(app), r'''
  declare -r app_path=''' + build_app_runner_relative_path(app, get_app_path(app)) + r'''
  declare -r browser_path=''' + build_app_runner_relative_path(app, install_app_browser(app)) + r'''
  declare -r cache_path=''' + build_app_runner_relative_path(app, get_app_cache_path(app)) + r'''
  declare -r distribution_path=''' + build_app_runner_relative_path(app, get_app_distribution_path(app)) + r'''
  declare -r executable_arguments=(''' + sanitize_app_command(app, sanitize_command(query_appfile(app, 'executable'))) + r''')
  declare -r firejail_options=(''' + sanitize_command(query_appfile(app, 'firejail')) + r''')
  declare -r firejail_options_path=''' + build_app_runner_relative_path(app, get_app_firejail_options_path(app)) + r'''
  declare -r root_path=''' + build_app_runner_relative_path(app, get_app_root_path(app)) + r'''
  declare -r urls_path=''' + build_app_runner_relative_path(app, os.path.join(get_app_path(app), 'urls')) + r'''

  # shellcheck disable=SC2088
  declare -r firejail_blacklisted_paths=(
    ''' + '\n    '.join(quote_argument(path) for path in get_firejail_blacklisted_paths()) + r'''
  )

  function build_directory_list {
    declare -n result_directory_list=$1
    shift

    declare directory_paths=()
    declare path
    for path; do
      [[ ! -d $path ]] || directory_paths+=("$path")
    done
    readonly directory_paths

    if [[ ${directory_paths-} ]]; then
      declare -r ifs=$IFS
      IFS=:
      result_directory_list=${directory_paths[*]}
      IFS=$ifs
    fi

    readonly result_directory_list 2> /dev/null
  }

  function build_environment {
    declare -n result_environment=$1
    shift

    result_environment=()

    build_directory_list result_environment\[PYTHONPATH\] "$distribution_path"/usr/lib/python*/dist-packages "$root_path"/usr/lib/python*{,/dist-packages,/plat-*}
    build_library_path result_environment\[LD_LIBRARY_PATH\]
    result_environment[PATH]=$PATH:$root_path/usr/bin:$root_path/bin
    result_environment[PYTHONHOME]=$root_path/usr

    LD_LIBRARY_PATH=${result_environment[LD_LIBRARY_PATH]-} build_gdk_pixbuf_path result_environment\[GDK_PIXBUF_MODULE_FILE\]

    [[ ${executable_path-} ]] || get_executable_path executable_path
    [[ $executable_path != ./AppRun ]] || result_environment[APPDIR]=$distribution_path

    if type firejail &> /dev/null; then
      result_environment[BROWSER]=$browser_path
      result_environment[TUXAPP_URLS]=$urls_path
    fi

    readonly result_environment
  }

  function build_firejail_arguments {
    declare -n result_firejail_arguments=$1
    declare -n argument_environment=$2
    shift 2

    result_firejail_arguments=(firejail --protocol="unix,inet,inet6,netlink")

    [[ ! ${TUXAPP_TRACE-} ]] || result_firejail_arguments+=(--allow-debuggers)

    declare name
    for name in "${!argument_environment[@]}"; do
      result_firejail_arguments+=(--env="$name=${argument_environment[$name]}")
    done

    result_firejail_arguments+=(--read-only="$root_path" --blacklist="$cache_path")

    declare path
    for path in "${app_path%/*}"/*; do
      [[ ! -d $path || $path == "$app_path" ]] || result_firejail_arguments+=(--blacklist="$path")
    done

    declare path
    for path in "${firejail_blacklisted_paths[@]}"; do
      [[ ! -e ${path/#~/$HOME} ]] || result_firejail_arguments+=(--blacklist="$path")
    done

    [[ ${executable_path-} ]] || get_executable_path executable_path
    declare -r profile_path=/etc/firejail/${executable_path##*/}.profile
    if [[ -f $profile_path ]]; then
      declare profile
      profile=$(< "$profile_path")
      if [[ $profile =~ include\ ([^$'\n']) ]]; then
        declare -r included_path=/etc/firejail/${BASH_REMATCH[1]}.profile
        [[ ! -f $included_path ]] || profile=$(< "$included_path")
      fi
      readonly profile

      [[ $profile != *whitelist\ * ]] || result_firejail_arguments+=(--whitelist={"$distribution_path","$root_path"})
    fi

    declare app_firejail_options
    read_firejail_options app_firejail_options

    result_firejail_arguments+=("${firejail_options[@]}" "${app_firejail_options[@]}")

    readonly result_firejail_arguments
  }

  function build_gdk_pixbuf_path {
    declare -n result_gdk_pixbuf_path=$1
    shift

    declare -r gdk_pixbuf_paths=(/usr/lib/*-linux-gnu/gdk-pixbuf-2.0)
    if [[ ! -d ${gdk_pixbuf_paths[0]} ]]; then
      declare path
      for path in "$root_path"/usr/lib/*-linux-gnu/gdk-pixbuf-2.0/*; do
        if [[ -d $path ]]; then
          result_gdk_pixbuf_path=$path/loaders.cache
          [[ -f $result_gdk_pixbuf_path ]] || "${path%/*}"/gdk-pixbuf-query-loaders "$path"/loaders/* > "$result_gdk_pixbuf_path"
        fi
      done
    fi

    readonly result_gdk_pixbuf_path 2> /dev/null
  }

  function build_library_path {
    # shellcheck disable=SC2034
    declare -n result_library_path=$1
    shift

    declare library_paths=()
    declare path
    for path in "$distribution_path"{,/opt/*} "$root_path" ''; do
      if [[ -d $path ]]; then
        declare relative_path
        for relative_path in {,/usr}/lib{,32,64} {,/usr}/lib/{i386,x86_64}-linux-gnu /usr/lib/{i386,x86_64}-linux-gnu/{alsa-lib,mesa,pulseaudio}; do
          library_paths+=("$path$relative_path")
        done
      fi
    done
    readonly library_paths

    build_directory_list result_library_path "${library_paths[@]}"
  }

  function build_strace_arguments {
    declare -n result_strace_arguments=$1
    shift

    result_strace_arguments=()
    [[ ! ${TUXAPP_TRACE-} ]] || result_strace_arguments+=(strace -f -e open,openat)
    readonly result_strace_arguments
  }

  function check_firejail {
    if type firejail &> /dev/null; then
      declare app_firejail_options
      read_firejail_options app_firejail_options

      [[ ${WAYLAND_DISPLAY-} || " ${firejail_options[@]} ${app_firejail_options[@]} " == " --x11[ =]" ]] || echo ''' + quote_argument(get_firejail_message('x11')) + r''' >&2
      [[ ! ${firejail_options-} ]] || echo ''' + quote_argument(get_firejail_message('options')).format('\'"${firejail_options[*]}"\'') + r''' >&2
    else
      [[ ${TUXAPP_TEST-} ]] || echo ''' + quote_argument(get_firejail_message('missing')) + r''' >&2
    fi
  }

  function get_executable_path {
    declare -n result_executable_path=$1
    shift

    result_executable_path=/dev/null
    declare argument
    for argument in "${executable_arguments[@]}"; do
      if [[ $argument == ./* ]]; then
        result_executable_path=$argument
        break
      fi
    done

    readonly result_executable_path
  }

  function listen_urls {
    [[ -f $urls_path ]] || touch "$urls_path"
    while read -r; do
      setsid xdg-open "$REPLY" &
    done < <(tail -f -n 0 --pid=$$ "$urls_path" 2> /dev/null) &
  }

  function main {
    check_firejail

    declare -A environment
    build_environment environment

    if type firejail &> /dev/null; then
      listen_urls

      declare firejail_arguments
      build_firejail_arguments firejail_arguments environment
    else
      declare name
      for name in "${!environment[@]}"; do
        export "$name=${environment[$name]}"
      done

      declare -r firejail_arguments=()
    fi

    declare strace_arguments
    build_strace_arguments strace_arguments

    cd "$distribution_path"
    exec "${firejail_arguments[@]}" "${strace_arguments[@]}" "${executable_arguments[@]}" "$@"
  }

  function read_firejail_options {
    declare -n result_firejail_options=$1
    shift

    result_firejail_options=()
    [[ ! -f $firejail_options_path ]] || eval "result_firejail_options=($(< "$firejail_options_path"))"
    readonly result_firejail_options
  }

  main "$@"
  ''')

is_app_installed = lambda app: \
  os.path.isfile(get_app_version_path(app)) and \
  os.path.isdir(get_app_distribution_path(app))

is_app_updated = lambda app: \
  is_app_installed(app) and \
  read_app_version(app) == request_app_version(app) and \
  read_app_download_urls_hash(app) == hash_app_download_urls(app)

is_file_executable = lambda path: \
  os.path.isfile(path) and \
  os.access(path, os.X_OK) and \
  os.path.splitext(path)[1] != '.so'

is_file_list_nested = lambda paths: all(path.lstrip('./').split('/', 1)[0] == paths[0].lstrip('./').split('/', 1)[0] for path in paths)

is_file_magic_number = lambda path, magic_number: read_file_binary(path, len(magic_number)) == magic_number

is_file_newer = lambda path, reference_path: get_file_mtime(path) > get_file_mtime(reference_path)

is_silent = lambda: getattr(silence, 'is_silent', False)

is_tarball_nested = lambda path: is_file_list_nested(read_process(('tar', '-t', '-f', path)).splitlines())

is_zip_file_nested = lambda path: is_file_list_nested(zipfile.ZipFile(path).namelist())

join_arguments = lambda arguments: ' '.join(quote_argument(argument) for argument in arguments)

list_all_apps = \
  output(lambda *args, **kwargs: '\n'.join(kwargs['result']))(
    lambda: tuple(request_grep_url(build_github_api_url('repos/{}/contents/apps'.format(get_github_repository())), ('-Po', r'(?<="name": ")(?!\.)[^"]+')).splitlines())
  )

list_app_distribution = lambda app: (os.path.join(path, filename) for path, directories, filenames in os.walk(get_app_distribution_path(app)) if '/node_modules/' not in path for filename in filenames)

list_installed_apps = \
  output(lambda *args, **kwargs: '\n'.join('{} {}'.format(app, version) for app, version in kwargs['result']))(
    lambda: tuple((app, read_app_version(app)) for app in get_installed_apps())
  )

main = \
  handle_exceptions(
  check('Exit with error')(
    lambda: \
      list_all_apps() \
        if parse_arguments().all else \
      check_apps_updated(check_app_installed(extract_app(argument)) for argument in parse_arguments().arguments or get_installed_apps()) \
        if parse_arguments().check else \
      execute_app(check_app_installed(extract_app(parse_arguments().arguments[0])), tuple(parse_arguments().arguments[1:])) \
        if parse_arguments().execute and parse_arguments().arguments else \
      list_installed_apps() \
        if parse_arguments().list else \
      purge_cache() \
        if parse_arguments().purge else \
      all(remove_app(check_app_installed(extract_app(argument))) for argument in parse_arguments().arguments) \
        if parse_arguments().remove else \
      all(install_app(check_app_installed(extract_app(argument))) for argument in parse_arguments().arguments or get_installed_apps()) \
        if parse_arguments().update else \
      all(install_app(extract_app(argument)) for argument in parse_arguments().arguments) \
        if parse_arguments().arguments else \
      parse_arguments(('-h',))
  ))

make_file_directories = lambda path: \
  make_directories(os.path.dirname(path)) and \
  path

move_directory = lambda path, destination_path: \
  copy_directory(path, destination_path) and \
  remove_directory_ascending(path) and \
  destination_path

parse_appfile = lambda app: dict(line.split('=', 1) for line in read_appfile(app).splitlines())

patch_app_package = lambda app, package: \
  write_bash_script(get_app_root_binary_path(app, 'lsb_release'), r'''
  [[ ! -x /usr/bin/lsb_release ]] || exec /usr/bin/lsb_release "$@"
  echo 'No LSB modules are available.' 2> /dev/null
  ''') \
    if package == 'lsb-release' else \
  write_file(get_app_root_binary_path(app, 'qt.conf'), textwrap.dedent('''\
  [Paths]
  Data = ../../share/qt5
  LibraryExecutables = qt5/libexec
  Plugins = qt5/plugins
  Prefix = {}
  Translations = ../../share/qt5/translations
  ''').format(next(glob.iglob(os.path.join(get_app_root_path(app), 'usr/lib/*-linux-gnu'))))) and \
  symlink_file(get_app_root_binary_path(app, 'qt.conf'), os.path.join(next(glob.iglob(os.path.join(get_app_root_path(app), 'usr/lib/*-linux-gnu'))), 'qt5/libexec/qt.conf')) \
    if package in ('python-pyqt5', 'python3-pyqt5') else \
  True

purge_cache = \
  log_after('Purged cache')(
    lambda: remove_directory(get_cache_path())
  )

query_app_data = lambda app, key, default='': (connect_app_data(app).execute('SELECT value FROM items WHERE key = ?', (build_data_key(key),)).fetchone() or (default,))[0]

query_app_package_data = \
  check(lambda app, package, *args, **kwargs: kwargs['result'] is None and 'Unknown package: {}'.format(package))(
    lambda app, package, key: query_app_data(app, (package, key), None)
  )

query_app_package_list_update_time = lambda app, url: int(query_app_data(app, ('packages', hash_md5(url), 'update-time'), '0'))

query_app_package_version = lambda app, package: extract_package_version(parse_url(query_app_package_data(app, package, 'url')).path)

query_appfile = lambda app, key: \
  query_appfile_download_urls(app) \
    if key == 'download-urls' else \
  query_appfile_value(app, 'executable').replace('{dist}', quote_argument(get_app_distribution_path(app))).replace('{root}', quote_argument(get_app_root_path(app))) \
    if key == 'executable' else \
  expand_package_groups(query_appfile_value(app, 'packages').split()) \
    if key == 'packages' else \
  query_appfile_value(app, key).lstrip('~') \
    if key in ('description', 'name', 'title') else \
  query_appfile_value(app, key)

query_appfile_download_urls = \
  check('No download URL of {} for your architecture')(
    lambda app: tuple(filter_app_download_url(app, url) for url in uncheck('')(query_appfile_value)(app, 'download-{}-url'.format(detect_architecture())).split())
  )

query_appfile_value = \
  check(lambda app, key, *args, **kwargs: kwargs['result'] is None and 'Failed to get {}.{}'.format(app, key))(
    lambda app, key: parse_appfile(app).get(key)
  )

query_package_data_header = lambda path, key: parse_package_data_header(path).get(key)

read_app_download_urls_hash = lambda app: read_app_version_components(app)[-1]

read_app_firejail_options = lambda app: read_file(get_app_firejail_options_path(app))

read_app_package_version = lambda app, package: read_file(get_app_package_version_path(app, package)).rstrip()

read_app_version = lambda app: read_app_version_components(app)[0]

read_app_version_components = lambda app: tuple(read_file(get_app_version_path(app)).rstrip().rsplit(None, 1)) or ('',)

read_appfile = lambda app: read_file(get_appfile_path(app)) or request_appfile(app)

read_file_binary = lambda path, size=-1: read_file(path, size, True)

read_process = lambda arguments, is_stderr_redirected=False: read_process_binary(arguments, is_stderr_redirected).decode('utf-8', 'replace')

remove_app = \
  lock_app(
  log_after('Removed {}')(
    lambda app: \
      remove_directory(get_app_path(app)) and \
      remove_file(get_app_desktop_entry_path(app))
  ))

remove_directory_ascending = lambda path: \
  remove_directory(path) and \
  remove_empty_directories(os.path.dirname(path))

remove_file_ascending = lambda path: \
  remove_file(path) and \
  remove_empty_directories(os.path.dirname(path))

request_app_version = lambda app, pattern=None: request_app_version_memoized(app, query_appfile(app, 'version-url'), pattern or query_appfile(app, 'version-regex'))

request_app_version_memoized = \
  memoize_temporarily(
  log(lambda app, url, *args, **kwargs: 'Requesting the version number of {} on {}'.format(app, url))(
  check(lambda app, url, *args, **kwargs: 'Failed to request the version number of {} on {}'.format(app, url))(
    lambda app, url, pattern: search(pattern, silence(request_grep_url_all)(url, ('-Pao', '-m', '1', '--', pattern)).splitlines()[0], 0, 1).strip().replace(os.path.sep, '-')
  )))

request_appfile = \
  memoize_temporarily(
  check('{} was not found')(
    lambda app: uncheck()(request_url)(build_github_raw_url('apps/{}'.format(app)))
  ))

request_grep_url = \
  log('Requesting {}')(
  check('Failed to request and grep {}')(
    lambda url, arguments: \
      uncheck()(read_process)(r'{} | {} | {} | grep {} 2> /dev/null || :'.format(join_arguments(build_request_arguments(
        ('-Ss', url),
        ('-q', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command(), join_arguments(arguments))).rstrip('\n')
  ))

request_grep_url_all = \
  log('Requesting {}')(
  check('Failed to request and grep {}')(
    lambda url, arguments: \
      uncheck()(read_process)(r'( {} | {} ) 2>&1 | {} | grep {} 2> /dev/null || :'.format(join_arguments(build_request_arguments(
        ('-Ss', '-D', '/dev/stderr', url),
        ('-Sq', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command(), join_arguments(arguments))).rstrip('\n')
  ))

request_url = \
  log('Requesting {}')(
  check('Failed to request {}')(
    lambda url: \
      uncheck()(read_process)(r'{} | {} | {}'.format(join_arguments(build_request_arguments(
        ('-Ss', url),
        ('-q', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command()))
  ))

request_url_headers = \
  log('Requesting {}')(
  check('Failed to request {}')(
    lambda url: \
      uncheck()(read_process)(build_request_arguments(
        ('-ISs', '-X', 'GET', url),
        ('-Sq', '-O', '-', '--spider', url),
      ), get_request_command() == 'wget')
  ))

resolve_app_packages = lambda app, packages: tuple(sorted(set(extract_package_name(query_app_package_data(app, package, 'url')) for package in resolve_app_packages_recursive(app, packages))))

resolve_app_packages_recursive = lambda app, packages, resolved_packages=set(): \
  functools.reduce(lambda packages, package: \
    packages | \
    {package} | \
    resolve_app_packages_recursive(app, tuple(dependency for dependency in query_app_package_data(app, package, 'dependencies').split() if (dependency.startswith('lib') or not package.startswith('lib')) and dependency not in get_excluded_dependencies() and dependency not in resolved_packages), # pylint: disable=undefined-variable
  packages | {package}), packages, set())

resolve_outdated_app_packages = lambda app, packages: tuple(package for package in resolve_app_packages(app, packages) if not query_app_package_version(app, package) == read_app_package_version(app, package))

sanitize_app_command = lambda app, command: join_arguments(os.path.realpath(os.path.join(get_app_distribution_path(app), argument)).replace(get_app_distribution_path(app), '.', 1) if argument.startswith('./') else argument for argument in split_command(command))

sanitize_command = lambda command: join_arguments(split_command(command))

search = lambda pattern, string, flags=0, group=0: getattr(re.search(pattern, string, flags), 'group', lambda *args, **kwargs: '')(group)

unpack_app_appimage1_distribution = \
  log(lambda app, path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda app, path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      uncheck()(call_process)(
        build_app_bsdtar_arguments(app) + \
        ('-x', '-C', make_directories(get_app_distribution_path(app)), '-f', path)
      ) and \
      get_app_distribution_path(app)
  ))

unpack_app_appimage2_distribution = \
  log(lambda app, path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda app, path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      uncheck()(call_process)('cd {} && {} 2> /dev/null'.format(quote_argument(make_directories(get_app_path(app))), join_arguments(
        (('firejail', '--quiet') if is_existing_command('firejail') else ()) + \
        (change_file_mode(path, lambda mode: mode | stat.S_IXUSR), '--appimage-extract')
      ))) and \
      move_directory(os.path.join(get_app_path(app), 'squashfs-root'), get_app_distribution_path(app))
  ))

unpack_app_distribution = \
  check(lambda app, path, *args, **kwargs: 'Unknown file format of {}'.format(os.path.basename(path)))(
    lambda app, path: \
      unpack_app_appimage1_distribution(app, path) \
        if is_file_magic_number(path, b'\x7fELF\x02\x01\x01\x00AI\x01') else \
      unpack_app_appimage2_distribution(app, path) \
        if is_file_magic_number(path, b'\x7fELF\x02\x01\x01\x00AI\x02') else \
      unpack_app_package_distribution(app, path) \
        if is_file_magic_number(path, b'!<arch>\n') else \
      unpack_app_zip_distribution(app, path) \
        if is_file_magic_number(path, b'PK') else \
      unpack_app_tarball_distribution(app, path)
        if is_file_magic_number(path, b'\x1f\x8b') or is_file_magic_number(path, b'\xfd7zXZ\x00\x00') or is_file_magic_number(path, b'BZh') else \
      None
  )

unpack_app_package_distribution = lambda app, path: \
  unpack_package(path, get_app_distribution_path(app)) and \
  all(symlink_file(os.path.relpath(os.path.join(get_app_distribution_path(app), os.readlink(path).lstrip('/')), os.path.dirname(path)), path) for path in glob.iglob(get_app_distribution_binary_path(app, '*')) if os.path.islink(path) and os.readlink(path).startswith('/')) and \
  get_app_distribution_path(app)

unpack_app_tarball_distribution = \
  log(lambda app, path, *args, **kwargs: 'Preparing to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      unpack_tarball(path, get_app_distribution_path(app), ('--strip-components=1',) if is_tarball_nested(path) else ()) and \
      unpack_nested_app_distributions(app)
  )

unpack_app_zip_distribution = lambda app, path: \
  (move_directory(next(glob.iglob(os.path.join(unpack_zip_file(path, os.path.join(get_app_path(app), 'unpack')), '*'))), get_app_distribution_path(app)) if is_zip_file_nested(path) else unpack_zip_file(path, get_app_distribution_path(app))) and \
  unpack_nested_app_distributions(app)

unpack_nested_app_distributions = lambda app: \
  all(unpack_app_distribution(app, path) and remove_file_ascending(path) for path in list_app_distribution(app) if os.path.splitext(path)[1].lower() in ('.appimage', '.deb')) and \
  get_app_distribution_path(app)

unpack_package = \
  log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
  output(' ')(
    lambda path, output_path, options=(): \
      uncheck()(pipe_process_stdin)(open(path, 'rb'),
        ('tar', '-x', get_tar_filter_option(query_package_data_header(path, 'extension')), '-C', make_directories(output_path)) + \
        get_tar_progress_options() + \
        options,
      query_package_data_header(path, 'offset'), query_package_data_header(path, 'size')) and \
      output_path
  )))

unpack_tarball = \
  log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
  output(' ')(
    lambda path, output_path, options=(): \
      uncheck()(call_process)(
        ('tar', '-x', '-C', make_directories(output_path), '-f', path) + \
        get_tar_progress_options() + \
        options
      ) and \
      output_path
  )))

update_app_data = lambda app, key, value, is_deferred=False: \
  connect_app_data(app).execute('REPLACE INTO items (key, value) VALUES (?, ?)', (build_data_key(key), value)) and \
  (is_deferred or commit_app_data(app))

update_app_data_items = lambda app, items, is_deferred=False: \
  connect_app_data(app).executemany('REPLACE INTO items (key, value) VALUES (?, ?)', ((build_data_key(key), value) for key, value in items)) and \
  (is_deferred or commit_app_data(app))

update_app_package_list = \
  log('Updating the package list from {1}')(
  check('Failed to update the package list from {1}')(
    lambda app, url, path: \
      functools.reduce(lambda items, line: \
        # pylint: disable=undefined-variable
        update_app_package_list_items(app, items[:-1]) and \
        ({},) \
          if line == 'EOF' else \
        items[:-1] + (dict(items[-1], **dict((line.split(': ', 1),))),) \
          if line else \
        items + ({},) \
          if len(items) < 100 else \
        update_app_package_list_items(app, items) and \
        ({},),
      uncheck()(read_process_lines)(r'''
      xzgrep '^\($\|\(Depends\|Filename\|Package\|Pre-Depends\|Provides\): \)' {} | \
      sed 's/ ([^)]\+)//g; s/ | [^,]\+//g; s/:any//g; s/, / /g; s|^Filename: |\0{}/|' 2> /dev/null
      echo EOF
      '''.format(
        quote_argument(path),
        quote_argument('/'.join(url.split('/', 4)[:-1])),
      )), ({},)) and \
      commit_app_data(app) and \
      remove_file(path) and \
      update_app_data(app, ('packages', hash_md5(url), 'update-time'), int(time.time()))
  ))

update_app_package_list_items = lambda app, items: \
  (not any('Provides' in item for item in items) or update_app_package_list_items(app, tuple(dict(((key, value) for key, value in item.items() if key != 'Provides'), **{'Package': package}) for item in items if 'Provides' in item for package in item['Provides'].split()))) and \
  update_app_data_items(app, (((item['Package'], 'dependencies'), ' '.join(item[key] for key in ('Depends', 'Pre-Depends') if item.get(key))) for item in items), True) and \
  update_app_data_items(app, (((item['Package'], 'url'), item['Filename']) for item in items), True)

update_app_package_lists = lambda app: \
  (not next(glob.iglob(build_cached_app_package_data_path(app, '*')), None) or copy_file(sorted(glob.iglob(build_cached_app_package_data_path(app, '*')))[-1], get_app_data_path(app))) and \
  all(update_app_package_list(app, url, download_missing_app_file(app, url, build_app_package_list_download_path(app, url))) for url in build_app_package_list_urls(app) if query_app_package_list_update_time(app, url) < time.time() - 60 * 60 * 6 and request_last_modified(url) > query_app_package_list_update_time(app, url))

write_app_version = lambda app: write_file(get_app_version_path(app), '{} {}\n'.format(request_app_version(app), hash_app_download_urls(app)))

write_bash_script = lambda path, content: \
  write_executable_file(path, textwrap.dedent('''\
  #!/usr/bin/env bash
  set -eu -o pipefail
  ''') + textwrap.dedent(content))

write_executable_file = lambda path, content: change_file_mode(write_file(path, content), lambda mode: mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

if __name__ == '__main__':
  main()
