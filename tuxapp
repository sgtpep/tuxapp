#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import absolute_import, print_function, unicode_literals

import functools
import glob
import hashlib
import os
import platform
import re
import stat
import subprocess
import sys
import textwrap
import time
import zipfile

__version__ = '1.0.0'

def check(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message:
        assert result, built_message
      return result
    return wrapper
  return decorator

def check_process_exceptions(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    try:
      return function(*args, **kwargs)
    except KeyboardInterrupt:
      print(file=sys.stderr)
      raise AssertionError
    except subprocess.CalledProcessError as exception:
      raise AssertionError('Command exited with code {}: {}'.format(exception.returncode, exception.cmd if isinstance(exception.cmd, type('')) else join_arguments(exception.cmd).replace('\\\n', '').strip()))
  return wrapper

def do(action):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      action(*args, result=result, **kwargs)
      return result
    return wrapper
  return decorator

def handle_exceptions(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    try:
      result = function(*args, **kwargs)
      if not result:
        sys.exit(1)
    except AssertionError as exception:
      print_exception(exception)
      sys.exit(1)
    except KeyboardInterrupt:
      print(file=sys.stderr)
      sys.exit(130)
  return wrapper

def lock_app(function):
  @functools.wraps(function)
  def wrapper(app, *args, **kwargs):
    if read_app_lock(app) == os.getpid():
      return function(app, *args, **kwargs)
    else:
      wait_pid(lambda: read_app_lock(app))
      try:
        write_file(get_app_lock_path(app), str(os.getpid()))
        return function(app, *args, **kwargs)
      finally:
        remove_file_ascending(get_app_lock_path(app))
  return wrapper

def lock_app_package_data(function):
  @functools.wraps(function)
  def wrapper(app, *args, **kwargs):
    if query_app_package_data_lock(app) == os.getpid():
      return function(app, *args, **kwargs)
    else:
      wait_pid(lambda: query_app_package_data_lock(app))
      try:
        update_app_package_data(app, 'lock', os.getpid())
        return function(app, *args, **kwargs)
      finally:
        update_app_package_data(app, 'lock', '')
  return wrapper

def log(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      built_message = build_decorator_message(message, *args, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return function(*args, **kwargs)
    return wrapper
  return decorator

def log_after(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      built_message = build_decorator_message(message, *args, **kwargs)
      result = function(*args, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return result
    return wrapper
  return decorator

def log_result(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message and not is_silent():
        print(built_message, file=sys.stderr)
      return result
    return wrapper
  return decorator

def memoize(function):
  import collections
  cache = collections.OrderedDict()
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    key = '{}{}'.format(args, kwargs)
    if key not in cache:
      cache[key] = function(*args, **kwargs)
      if len(cache) > get_memoized_size():
        cache.popitem(False)
    return cache[key]
  if not hasattr(wrapper, '__wrapped__'):
    wrapper.__wrapped__ = function
  wrapper.remove = lambda *args, **kwargs: remove_memoized_cache(cache, *args, **kwargs)
  return wrapper

def memoize_temporarily(function):
  import collections
  cache = collections.OrderedDict()
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    key = '{}{}'.format(args, kwargs)
    if key not in cache or cache[key][1] < time.time() - get_memoized_time():
      cache[key] = function(*args, **kwargs), time.time()
      if len(cache) > get_memoized_size():
        cache.popitem(False)
    return cache[key][0]
  if not hasattr(wrapper, '__wrapped__'):
    wrapper.__wrapped__ = function
  wrapper.remove = lambda *args, **kwargs: remove_memoized_cache(cache, *args, **kwargs)
  return wrapper

def output(message):
  def decorator(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
      result = function(*args, **kwargs)
      built_message = build_decorator_message(message, *args, result=result, **kwargs)
      if built_message and not is_silent():
        print(built_message)
      return result
    return wrapper
  return decorator

def silence(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    if is_silent():
      return function(*args, **kwargs)
    else:
      silence.is_silent = True
      result = function(*args, **kwargs)
      del silence.is_silent
      return result
  return wrapper

def uncheck(function):
  @functools.wraps(function)
  def wrapper(*args, **kwargs):
    try:
      return function(*args, **kwargs)
    except AssertionError:
      return
  return wrapper

@check_process_exceptions
def call_process(arguments):
  subprocess.check_call(arguments, shell=isinstance(arguments, type('')))
  return True

def change_file_mode(path, get_mode):
  os.chmod(path, get_mode(os.stat(path).st_mode))
  return path

def check_app_firejail(app):
  if not is_silent():
    if is_existing_command('firejail'):
      if 'WAYLAND_DISPLAY' not in os.environ and not re.search(r' --x11[ =]', ' {} {} '.format(query_appfile(app, 'firejail'), read_app_firejail_options(app))):
        print(get_firejail_message('x11'), file=sys.stderr)
      if read_app_firejail_options(app):
        print(get_firejail_message('options').format(read_app_firejail_options(app)), file=sys.stderr)
    else:
      print(get_firejail_message('missing'), file=sys.stderr)
  return True

def commit_data(path):
  connect_data(path).commit()
  return True

@memoize
def connect_data_memoized(path):
  import sqlite3
  connection = sqlite3.connect(make_file_directories(path), 60 * 5)
  connection.execute('CREATE TABLE IF NOT EXISTS items (key TEXT PRIMARY KEY, value TEXT)')
  return connection

def copy_directory(path, destination_path):
  import distutils.dir_util
  distutils.dir_util._path_created = {} # pylint: disable=protected-access
  distutils.dir_util.copy_tree(path, destination_path, update=True)
  return destination_path

def copy_file(path, destination_path):
  import shutil
  shutil.copyfile(path, make_file_directories(destination_path))
  shutil.copystat(path, destination_path)
  return destination_path

def copy_file_content(file, destination_file, offset=0, size=None, chunk_size=65536):
  with file, destination_file:
    file.seek(offset)
    try:
      if size:
        try:
          import builtins
        except ImportError:
          import __builtin__ as builtins
        for _ in getattr(builtins, 'xrange', range)(size // chunk_size):
          destination_file.write(file.read(chunk_size))
        destination_file.write(file.read(size % chunk_size))
      else:
        import shutil
        shutil.copyfileobj(file, destination_file, chunk_size)
      return True
    except IOError:
      return False

def encode_url_parameters(parameters):
  try:
    from urllib.parse import urlencode
  except ImportError:
    from urllib import urlencode
  return urlencode(parameters)

def is_existing_command(command):
  import distutils.spawn
  return bool(distutils.spawn.find_executable(command))

def make_directories(path):
  if not os.path.isdir(path):
    os.makedirs(path)
  return path

@memoize
def parse_arguments(arguments=None):
  import argparse
  parser = argparse.ArgumentParser(description=get_description(), epilog=', '.join((get_license(), get_copyright(), build_github_url())))
  parser.add_argument('-a', '--all', action='store_true', help='list apps available for installation')
  parser.add_argument('-c', '--check', action='store_true', help='check installed apps for updates')
  parser.add_argument('-e', '--execute', action='store_true', help='execute an installed app')
  parser.add_argument('-l', '--list', action='store_true', help='list installed apps')
  parser.add_argument('-p', '--purge', action='store_true', help='purge cache')
  parser.add_argument('-r', '--remove', action='store_true', help='remove installed apps')
  parser.add_argument('-u', '--update', action='store_true', help='update installed apps')
  parser.add_argument('-v', '--version', action='version', version='{} {}'.format(get_name(), get_version()))
  parser.add_argument('arguments', help='an app name', metavar='app', nargs='*')
  parsed_arguments = parser.parse_args(arguments)
  return parsed_arguments

@memoize_temporarily
@check(lambda path, *args, **kwargs: 'Failed to parse {}'.format(os.path.basename(path)))
def parse_package_data_header(path):
  import contextlib
  import mmap
  with open(path, 'rb') as file, contextlib.closing(mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ)) as map_file:
    start = map_file.find(b'data.tar.')
    end = map_file.find(b'`\n', start)
    if start != -1 and end != -1:
      filename, _, _, _, _, size = map_file[start:end].decode('utf-8', 'replace').split()
      return {
        'extension': re.sub(r'\W.*$', '', filename.replace('data.tar.', '', 1)),
        'offset': end + 2,
        'size': int(size),
      }

def parse_url(url):
  try:
    from urllib.parse import urlsplit
  except ImportError:
    from urlparse import urlsplit
  return urlsplit(url)

@check_process_exceptions
def pipe_process_stdin(file, arguments, offset=0, size=None):
  process = subprocess.Popen(arguments, stdin=subprocess.PIPE)
  if copy_file_content(file, process.stdin, offset, size):
    return process.wait() == 0
  else:
    return False

def print_exception(exception):
  if exception.args:
    print(exception.args[0], file=sys.stderr)

def quote_argument(string):
  try:
    from shlex import quote
  except ImportError:
    from pipes import quote
  return quote(string)

def read_file(path, size=-1, is_binary=False):
  if os.path.isfile(path):
    import io
    with io.open(path, 'rb' if is_binary else 'r') as file:
      return file.read(size)
  else:
    return ''

@check_process_exceptions
def read_process_binary(arguments, is_stderr_redirected=False):
  return subprocess.check_output(arguments, shell=isinstance(arguments, type('')), stderr=subprocess.STDOUT if is_stderr_redirected else None)

@check_process_exceptions
def read_process_lines(arguments, is_stderr_redirected=False):
  process = subprocess.Popen(arguments, shell=isinstance(arguments, type('')), stderr=subprocess.STDOUT if is_stderr_redirected else None, stdout=subprocess.PIPE)
  for line in iter(process.stdout.readline, b''):
    yield line.decode('utf-8', 'replace').rstrip('\n')

def remove_directory(path):
  if os.path.isdir(path):
    import shutil
    shutil.rmtree(path)
  return True

def remove_empty_directories(path):
  try:
    os.removedirs(path)
  except OSError:
    pass
  return True

def remove_file(path):
  if os.path.isfile(path):
    os.remove(path)
  return True

def remove_memoized_cache(cache, *args, **kwargs):
  key = '{}{}'.format(args, kwargs)
  if key in cache:
    del cache[key]
  return True

def rename_file(path, destination_path):
  os.rename(path, make_file_directories(destination_path))
  return destination_path

def request_url_timestamp(url):
  import email.utils
  return time.mktime(email.utils.parsedate(search(r'(?<=\bLast-Modified: ).+$', request_url_headers(url), re.I | re.M)) or time.gmtime())

def split_command(command):
  try:
    import shlex
    return tuple(shlex.split(command))
  except ValueError:
    return ()

def symlink_file(path, target_path):
  if not os.path.islink(path) or os.readlink(path) != target_path:
    if os.path.islink(path):
      os.remove(path)
    os.symlink(target_path, make_file_directories(path))
  return path

def touch_file(path, timestamp=None):
  os.utime(path if os.path.isfile(path) else write_file(path), timestamp and (timestamp, timestamp))
  return path

@log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))
@check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))
def unpack_zip_file(path, output_path):
  try:
    with zipfile.ZipFile(path) as file:
      for info in file.infolist():
        file.extract(info.filename, make_directories(output_path))
        os.chmod(os.path.join(output_path, info.filename), info.external_attr >> 16)
      return output_path
  except Exception as exception: # pylint: disable=broad-except
    print_exception(exception)

def unquote_url(string):
  try:
    from urllib.parse import unquote
  except ImportError:
    from urllib import unquote
  return unquote(string)

def wait_pid(get_pid):
  previous_pid = None
  while True:
    pid = get_pid()
    if pid and os.path.isdir(os.path.join('/proc', str(pid))):
      if pid != previous_pid:
        previous_pid = pid
        if not is_silent():
          print('Waiting for the process {}'.format(pid), file=sys.stderr)
      time.sleep(1)
    else:
      break

def write_file(path, content='', is_append=False):
  import io
  with io.open(make_file_directories(path), 'a' if is_append else 'w') as file:
    file.write(content if isinstance(content, type('')) else content.decode('utf-8', 'replace'))
    return path

append_file = lambda path, content='': write_file(path, content, True)

build_app_distribution_filename = lambda app, url: \
  os.path.basename(parse_url(url).path) \
    if '.' in os.path.basename(parse_url(url).path) else \
  '-'.join((app, request_app_version(app), hash_md5(url)))

build_app_download_path = lambda app, url: build_download_path(get_app_downloads_path(app), url)

build_app_library_path = lambda app: \
  ':'.join(path for path in (get_app_root_path(app), get_app_distribution_path(app)) for path in (
    os.path.join(path, 'usr/lib', detect_library_directory_name()),
    os.path.join(path, 'lib', detect_library_directory_name()),
    os.path.join(path, 'usr/lib'),
  ))

build_app_package_list_urls = \
  check(lambda app, *args, **kwargs: 'Unknown package repository: {}'.format(query_appfile(app, 'package-repository')))(
    lambda app: \
      tuple(url.format(query_appfile(app, 'package-repository'), 'binary-{}/Packages.xz'.format(detect_debian_architecture())) for url in (
        (get_debian_mirror_url() + path for path in (
          'debian/dists/{}/main/{}',
          'debian-security/dists/{}/updates/main/{}',
        )) \
          if is_debian_repository(query_appfile(app, 'package-repository')) else \
        (get_ubuntu_mirror_url() + path for path in (
          'ubuntu/dists/{}/main/{}',
          'ubuntu/dists/{}/universe/{}',
          'ubuntu/dists/{}-security/main/{}',
        ))
      ))
  )

build_app_packages = \
  lambda app: tuple(sorted(set(
    detect_app_library_packages(app, detect_missing_app_libraries(app)) + \
    ('libudev1',) + \
    query_appfile(app, 'packages')
  )))

build_app_runner_relative_path = lambda app, path: re.sub(r'/\.$', '', os.path.join('${0%/*}', quote_argument(os.path.relpath(path, os.path.dirname(get_app_runner_path(app))))))

build_curl_request_arguments = lambda options, is_gzip=False: \
  ('curl', '-#Lf', '-H', 'Accept-Language: en', '-m', '10', '--retry', '2') + \
  (() if parse_url(options[-1]).netloc == 'downloads.sourceforge.net' else ('-A', get_user_agent())) + \
  (('-H', 'Accept-Encoding: gzip') if is_gzip else ()) + \
  options

build_data_key = lambda components: \
  components \
    if isinstance(components, type('')) else \
  ':'.join(components)

build_decorator_message = lambda string, *args, **kwargs: \
  string(*args, **kwargs) \
    if callable(string) else \
  string.format(*args, **kwargs)

build_desktop_entry_category = lambda category: \
  ('AudioVideo;' if category in ('audio', 'video') else '') + \
  '{};'.format(category.title())

build_download_path = lambda path, url: os.path.join(path, os.path.basename(parse_url(url).path))

build_firejail_arguments = lambda: \
  ('firejail', '--quiet') \
    if is_existing_command('firejail') else \
  ()

build_github_api_url = lambda path: 'https://api.github.com/{}'.format(path)

build_github_raw_url = lambda path: 'https://raw.githubusercontent.com/{}/master/{}'.format(get_github_repository(), path)

build_github_url = lambda url='': 'https://github.com/{}{}'.format(get_github_repository(), url and '/{}'.format(url))

build_request_arguments = lambda curl_options=(), wget_options=(), is_gzip=False: \
  build_curl_request_arguments(curl_options, is_gzip) \
    if get_request_command() == 'curl' else \
  build_wget_request_arguments(wget_options, is_gzip)

build_wget_request_arguments = lambda options, is_gzip=False: \
  ('wget', '-T', '10', '-t', '3', '-nv', '--header', 'Accept-Language: en') + \
  (() if parse_url(options[-1]).netloc == 'downloads.sourceforge.net' else ('-U', get_user_agent())) + \
  (('--header', 'Accept-Encoding: gzip') if is_gzip else ()) + \
  options

check_app_installed = \
  check('{} is not installed')(
    lambda app, is_soft=False: \
      (os.path.isdir(get_app_path(app)) if is_soft else is_app_installed(app)) and \
      app
  )

check_app_updated = \
  log_after(lambda app, *args, **kwargs: not is_existing_command('firejail') and resolve_outdated_app_packages(app, query_appfile(app, 'packages')) and 'Warning: packages of {} are outdated'.format(app))(
  log_result(lambda app, *args, **kwargs: \
    '{} {} is up to date'.format(app, read_app_version(app)) \
      if kwargs['result'] else \
    '{} can be updated from {} to {}'.format(app, read_app_version(app), request_app_version(app))
  )(
    lambda app: is_app_updated(app)
  ))

check_apps_updated = \
  output(lambda *args, **kwargs: \
    'No updates' \
      if all(is_updated for app, is_updated in kwargs['result']) else \
    'Updates available: {}'.format(', '.join('{} {}'.format(app, request_app_version(app)) for app, is_updated in kwargs['result'] if not is_updated))
  )(
    lambda apps: tuple((app, check_app_updated(app)) for app in apps)
  )

check_detected_app_library_packages = \
  check(lambda packages, *args, **kwargs: kwargs['result'] is False and 'Failed to detect packages for libraries: {}'.format(', '.join(library for library, package in packages.items() if not package)))(
    lambda packages: \
      all(package for library, package in packages.items()) and \
      packages
  )

connect_data = lambda path: \
  (os.path.isfile(path) or connect_data_memoized.remove(path)) and \
  connect_data_memoized(path)

copy_updated_file = lambda path, destination_path: \
  copy_file(path, destination_path) \
    if is_file_newer(path, destination_path) else \
  destination_path

detect_app_library_packages = \
  log('Detecting library packages')(
    lambda app, libraries: \
      tuple(sorted(set(
        tuple(package for package in (query_app_package_data(app, (library, 'package')) for library in libraries) if package) + \
        tuple(check_detected_app_library_packages(dict(functools.reduce(lambda items, line: \
          items + ((line.lstrip(' '), None),) \
            if line.startswith(' ') else \
          items \
            if is_library_package_ignored(line) or items[-1][1] else \
          update_app_package_data(app, (items[-1][0], 'package'), line) and \
          items[:-1] + ((items[-1][0], line),),
        request_app_library_packages(app, libraries), ()))).values())
      )))
  )

detect_architecture = \
  check(lambda *args, **kwargs: 'Unknown architecture: {}'.format(platform.machine()))(
    lambda: \
      {
        'i386': 'x86',
        'i686': 'x86',
        'ia64': 'x86-64',
        'x86_64': 'x86-64',
      }.get(platform.machine())
  )

detect_debian_architecture = \
  check(lambda *args, **kwargs: 'Unsupported architecture: {}'.format(detect_architecture()))(
    lambda: \
      {
        'x86': 'i386',
        'x86-64': 'amd64',
      }.get(detect_architecture())
  )

detect_library_directory_name = lambda: \
  '{}-linux-gnu'.format({
    'amd64': 'x86_64',
    'i386': 'i386',
  }.get(detect_debian_architecture()))

detect_missing_app_libraries = lambda app: \
  install_app_packages(app, ('libc-bin',)) and \
  detect_missing_app_libraries_verbose(app)

detect_missing_app_libraries_ldd = lambda app, paths: \
  tuple(sorted(set(library for library in (line.split(' => ', 1)[0].lstrip('\t') for line in (uncheck(read_process)('{} || :'.format(join_arguments(
    build_firejail_arguments() + \
    ('env', 'LC_ALL=C', get_app_root_binary_path(app, 'ldd')) + \
    paths
  ))) or '').splitlines() if line.endswith(' not found') or ' => ' in line and ' {}/'.format(get_app_path(app)) not in line) if not library.startswith('/') and not any(os.path.basename(path) == library for path in paths) and library not in query_appfile(app, 'ignored-libraries'))))

detect_missing_app_libraries_verbose = \
  log('Detecting missing libraries')(
    lambda app: detect_missing_app_libraries_ldd(app, list_directory_elf_files(get_app_distribution_path(app)))
  )

download_app_file = \
  log('Downloading {1}')(
  check('Failed to download {1}')(
    lambda app, url, path: \
      rename_file_ascending(build_app_download_path(app, path), path) \
        if uncheck(call_process)(build_request_arguments(
          (('-Ss',) if is_silent() else ()) + \
          ('-o', make_file_directories(build_app_download_path(app, path)), url),
          (('-q',) if is_silent() else ('--show-progress',)) + \
          ('-O', make_file_directories(build_app_download_path(app, path)), url),
        )) else \
      remove_file_ascending(build_app_download_path(app, path)) and \
      None
  ))

download_app_files = \
  log(lambda app, urls, *args, **kwargs: urls and 'Downloading {}'.format(urls[0] if len(urls) == 1 else '{} files'.format(len(urls))))(
  check(lambda app, urls, *args, **kwargs: kwargs['result'] is None and 'Failed to download {}'.format(urls[0] if len(urls) == 1 else 'files'))(
    lambda app, urls, path: \
      () \
        if not urls else \
      tuple(rename_file_ascending(build_app_download_path(app, url), build_download_path(path, url)) for url in urls if os.path.isfile(build_app_download_path(app, url))) \
        if (download_app_files_curl(app, urls, path) if get_request_command() == 'curl' else download_app_files_wget(app, urls, path)) else \
      all(remove_file_ascending(build_app_download_path(app, url)) for url in urls) and \
      None
  ))

download_app_files_curl = lambda app, urls, path: \
  uncheck(call_process)(build_curl_request_arguments(
    (('-Ss',) if is_silent() else ()) + \
    tuple(argument for url in urls for argument in ('-o', make_file_directories(build_app_download_path(app, url)), url))
  )) and \
  all(os.path.isfile(build_app_download_path(app, url)) for url in urls)

download_app_files_wget = lambda app, urls, path: \
  all(remove_file(build_app_download_path(app, url)) for url in urls) and \
  uncheck(call_process)(build_wget_request_arguments(
    (('-q',) if is_silent() else ('--show-progress',)) + \
    ('-P', make_directories(get_app_downloads_path(app))) + \
    urls
  ))

download_app_packages = lambda app, packages: \
  tuple(copy_file(path, get_app_temp_file_path(app, path)) for path in (get_app_cached_file_path(app, parse_url(query_app_package_url(app, package)).path) for package in packages) if os.path.isfile(path)) + \
  download_missing_app_temp_files(app, set(url for url in (query_app_package_url(app, package) for package in packages) if not os.path.isfile(get_app_cached_file_path(app, parse_url(url).path))))

download_missing_app_file = lambda app, url, path: \
  path \
    if os.path.isfile(path) else \
  download_app_file(app, url, path)

download_missing_app_files = lambda app, urls, path: \
  tuple(path for path in (build_download_path(path, url) for url in urls) if os.path.isfile(path)) + \
  download_app_files(app, tuple(url for url in urls if not os.path.isfile(build_download_path(path, url))), path)

download_missing_app_temp_file = lambda app, url: download_missing_app_file(app, url, build_download_path(get_app_temp_path(app), url))

download_missing_app_temp_files = lambda app, urls: download_missing_app_files(app, urls, get_app_temp_path(app))

execute_app = lambda app, arguments=(): execute_process((get_app_runner_path(app),) + arguments)

execute_process = lambda arguments: os.execvp(arguments[0], arguments)

expand_package_group = lambda group: get_package_groups().get(group, (group,))

expand_package_groups = lambda packages: tuple(package for package in packages for package in expand_package_group(package))

extract_app = lambda string: os.path.basename(string)

extract_package_name = lambda path: os.path.basename(path).split('_', 1)[0]

extract_package_version = lambda path: path.split('_', 2)[1]

filter_app_download_url = lambda app, url: url.replace('{debian}', '{}debian/pool'.format(get_debian_mirror_url())).replace('{ubuntu}', '{}ubuntu/pool'.format(get_ubuntu_mirror_url())).replace('{version}', request_app_version(app))

get_app_cached_file_path = lambda app, path: os.path.join(get_cache_path(), query_appfile(app, 'package-repository'), os.path.basename(path))

get_app_desktop_entry_path = lambda app: os.path.join(get_xdg_data_path(), 'applications/{}-{}.desktop'.format(get_name(), app))

get_app_distribution_binary_path = lambda app, filename: get_app_distribution_file_path(app, os.path.join('usr/bin', filename))

get_app_distribution_file_path = lambda app, path: os.path.join(get_app_distribution_path(app), path)

get_app_distribution_path = lambda app: os.path.join(get_app_path(app), 'dist')

get_app_downloads_path = lambda app: os.path.join(get_app_path(app), 'downloads')

get_app_dynamic_linker_path = lambda app: next(glob.iglob(get_app_root_file_path(app, os.path.join('lib', detect_library_directory_name(), 'ld-linux*.so.2'))))

get_app_firejail_options_path = lambda app: os.path.join(get_app_path(app), 'firejail')

get_app_icon_path = lambda app: os.path.join(get_app_path(app), 'icon')

get_app_library_packages_request_size = lambda: 10

get_app_lock_path = lambda app: os.path.join(get_app_path(app), 'lock')

get_app_package_data_path = lambda app: os.path.join(get_cache_path(), query_appfile(app, 'package-repository'), 'packages')

get_app_package_version_path = lambda app, package: get_app_root_file_path(app, os.path.join('var/lib/packages', package))

get_app_patchelf_file_path = lambda app, path: os.path.join(get_app_patchelf_path(app), os.path.basename(path))

get_app_patchelf_path = lambda app: get_app_root_file_path(app, 'usr/lib/patchelf')

get_app_path = lambda app: os.path.join(os.path.expanduser('~/.{}'.format(get_name())), app)

get_app_root_binary_path = lambda app, filename: get_app_root_file_path(app, os.path.join('usr/bin', filename))

get_app_root_file_path = lambda app, path: os.path.join(get_app_root_path(app), path)

get_app_root_path = lambda app: os.path.join(get_app_path(app), 'root')

get_app_runner_path = lambda app: os.path.join(get_app_path(app), 'run')

get_app_temp_file_path = lambda app, path: os.path.join(get_app_temp_path(app), os.path.basename(path))

get_app_temp_path = lambda app: os.path.join(get_app_path(app), 'temp')

get_app_version_path = lambda app: os.path.join(get_app_path(app), 'version')

get_appfile_path = lambda app: os.path.join(get_project_path(), 'apps', app)

get_cache_path = lambda: os.path.join(get_xdg_cache_path(), 'tuxapp')

get_copyright = lambda: '(c) {} Danil Semelenov'.format(get_copyright_range())

get_copyright_range = lambda: '{}{}'.format(get_copyright_year(), time.strftime('-%Y') if int(time.strftime('%Y')) > get_copyright_year() else '')

get_copyright_year = lambda: 2017

get_debian_mirror_url = lambda: 'https://cdn-aws.deb.debian.org/'

get_description = lambda: 'Downloads and installs the latest official releases of Linux® applications including dependencies without root permissions and allows to run them sandboxed.'

get_file_mtime = lambda path: \
  os.path.getmtime(path) \
    if os.path.isfile(path) else \
  0

get_firejail_blacklisted_paths = lambda: \
  (
    '~/.electron-cash',
    '~/.passwd-s3fs',
    '~/.s3cmd',
  )

get_firejail_message = lambda name: \
  {
    'missing': 'Warning: firejail is not installed on your system and will not be used to sandbox this app.{}'.format(get_package_install_command('firejail', ' Install it with the command: {}')),
    'options': 'Warning: firejail will run this app with custom options: {}',
    'x11': 'Warning: X11 sandboxing is not enabled for this app.', # 'To prevent it from reading any window contents and input events install this app with the --x11 option.',
  }[name]

get_github_repository = lambda: 'sgtpep/{}'.format(get_name())

get_installed_apps = \
  check('No apps are installed')(
    lambda: tuple(sorted(os.path.basename(os.path.dirname(path)) for path in glob.iglob(get_app_version_path('*'))))
  )

get_license = lambda: 'MIT License'

get_memoized_size = lambda: 128

get_memoized_time = lambda: 5 * 60

get_name = lambda: 'tuxapp'

get_package_exclusions = lambda package: \
  (
    '/etc',
    '/sbin',
    '/usr/sbin',
    '/var',
  ) + \
  (('/bin', '/usr/bin') if package.startswith('lib') and package not in ('libarchive-tools', 'libc-bin') else ()) + \
  (() if package == 'libqt5webengine-data' else ('/usr/share',))

get_package_groups = lambda: \
  {
    'group-chromium': (
      'libasound2',
      'libgconf-2-4',
      'libgl1-mesa-dri',
      'libgl1-mesa-glx',
      'libgtk-3-0',
      'libnss3',
      'libxss1',
      'libxtst6',
    ),
    'group-electron': (
      'libasound2',
      'libgconf-2-4',
      'libgtk2.0-0',
      'libnss3',
      'libpulse0',
      'libudev1',
      'libxkbfile1',
      'libxss1',
      'libxtst6',
    ),
    'group-firefox': (
      'libdbus-glib-1-2',
      'libgtk-3-0',
      'libxt6',
    ),
    'group-opengl': (
      'libgl1-mesa-dri',
      'libgl1-mesa-glx',
    ),
  }

get_package_install_command = lambda package, message='{}': \
  message.format('sudo apt install {}'.format(package)) \
    if is_existing_command('apt') else \
  message.format('sudo apt-get install {}'.format(package)) \
    if is_existing_command('apt-get') else \
  message.format('sudo dnf install {}'.format(package)) \
    if is_existing_command('dnf') else \
  message.format('sudo pacman -S {}'.format(package)) \
    if is_existing_command('pacman') else \
  message.format('sudo yum install {}'.format(package)) \
    if is_existing_command('yum') else \
  message.format('sudo zypper install {}'.format(package)) \
    if is_existing_command('zypper') else \
  ''

get_project_path = lambda: os.path.dirname(os.path.realpath(__file__.rstrip('c')))

get_request_command = \
  check('Neither wget nor curl is installed')(
    lambda: \
      'wget' \
        if is_existing_command('wget') and not os.environ.get('TUXAPP_CURL') else \
      'curl' \
        if is_existing_command('curl') else \
      None
  )

get_request_gzip_command = lambda: 'gzip -df 2> /dev/null'

get_request_head_command = lambda: 'head -c 1000000 2> /dev/null'

get_tar_filter_option = \
  check('Unknown archive extension: {}')(
    lambda extension: \
      {
        'bz2': '-j',
        'gz': '-z',
        'lzma': '--lzma',
        'xz': '-J',
      }.get(extension)
  )

get_tar_progress_options = lambda: \
  () \
    if is_silent() else \
  ('--checkpoint=.250',)

get_ubuntu_mirror_url = lambda: 'http://archive.ubuntu.com/'

get_user_agent = lambda: 'Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'

get_version = lambda: __version__

get_xdg_cache_path = lambda: os.environ.get('XDG_CACHE_HOME', os.path.expanduser('~/.cache'))

get_xdg_data_path = lambda: os.environ.get('XDG_DATA_HOME', os.path.expanduser('~/.local/share'))

hash_app_download_urls = lambda app: hash_md5(' '.join(query_appfile(app, 'download-urls')))

hash_md5 = lambda string: hashlib.md5(string.encode('utf-8', 'replace')).hexdigest()

install_app = \
  lock_app(
  log(lambda app, *args, **kwargs: \
    None \
      if is_app_updated(app) else \
    'Updating {} from {} to {}'.format(app, read_app_version(app), request_app_version(app)) \
      if is_app_installed(app) else \
    'Installing {} {}'.format(app, request_app_version(app))
  )(
  log_after(lambda app, *args, **kwargs: \
    '{} {} is up to date'.format(app, read_app_version(app)) \
      if is_app_updated(app) else \
    'Updated {} from {} to {}'.format(app, read_app_version(app), request_app_version(app)) \
      if is_app_installed(app) else \
    'Installed {} {}'.format(app, request_app_version(app))
  )(
    lambda app: \
      install_app_distribution(app) and \
      install_app_packages(app) and \
      install_app_runner(app) and \
      check_app_firejail(app) and \
      install_app_desktop_entry(app) and \
      get_app_path(app)
  )))

install_app_browser = lambda app: \
  write_bash_script(get_app_root_binary_path(app, 'browser'), r'''
  echo "$1" > "$TUXAPP_URLS"
  ''')

install_app_desktop_entry = \
  log_after(lambda app, *args, **kwargs: not os.path.isfile(get_app_desktop_entry_path(app)) and 'Added the menu item: {}'.format(query_appfile(app, 'name')))(
    lambda app: \
      write_file(get_app_desktop_entry_path(app), textwrap.dedent('''\
      [Desktop Entry]
      Categories={category}
      Comment={title}
      Exec={runner_path} %U
      Icon={icon_path}
      Name={name}
      TryExec={runner_path}
      Type=Application
      {appendix}''').format(
        appendix=query_appfile(app, 'desktop-entry'),
        category=build_desktop_entry_category(query_appfile(app, 'category')),
        icon_path=install_app_icon(app),
        name=query_appfile(app, 'name'),
        runner_path=get_app_runner_path(app),
        title=query_appfile(app, 'title'),
      ))
  )

install_app_distribution = lambda app: \
  get_app_distribution_path(app) \
    if is_app_updated(app) else \
  all(unpack_app_distribution(app, path) for path in tuple(download_missing_app_file(app, url, get_app_temp_file_path(app, build_app_distribution_filename(app, url))) for url in query_appfile(app, 'download-urls'))) and \
  patch_app_elf_files(app, get_app_distribution_path(app)) and \
  write_app_version(app) and \
  all(remove_file(path) for path in glob.iglob(get_app_temp_file_path(app, '*'))) and \
  remove_file(get_app_icon_path(app)) and \
  get_app_distribution_path(app)

install_app_icon = lambda app: uncheck(download_missing_app_file)(app, query_appfile(app, 'icon-url'), get_app_icon_path(app))

install_app_package_file = lambda app, path: \
  silence(unpack_package)(path, get_app_root_path(app), tuple('--exclude=.{}'.format(exclusion) for exclusion in get_package_exclusions(extract_package_name(path)))) and \
  patch_app_package(app, extract_package_name(path)) and \
  extract_package_name(path)

install_app_package_files = \
  log(lambda app, paths, *args, **kwargs: paths and 'Installing packages: {}'.format(', '.join(extract_package_name(path) for path in paths)))(
    lambda app, paths: \
      all(install_app_package_file(app, path) for path in paths) and \
      (not paths or any(extract_package_name(path) == 'patchelf' for path in paths) or patch_app_elf_files(app, get_app_root_path(app))) and \
      all(write_app_package_file_version(app, path) for path in paths)
  )

install_app_packages = lambda app, packages=None: \
  update_app_package_lists(app) and \
  install_app_package_files(app, download_app_packages(app, resolve_outdated_app_packages(app, packages or build_app_packages(app)))) and \
  all(remove_file(path) if os.path.isfile(get_app_cached_file_path(app, path)) else rename_file(path, get_app_cached_file_path(app, path)) for path in glob.iglob(get_app_temp_file_path(app, '*.deb'))) and \
  remove_old_files(get_app_cached_file_path(app, '*.deb'))

install_app_patchelf = lambda app: \
  install_app_packages(app, ('patchelf',)) and \
  all(copy_updated_file(os.path.realpath(get_app_root_file_path(app, path.format(detect_library_directory_name()))), get_app_patchelf_file_path(app, path)) for path in (
    'lib/{}/libc.so.6',
    'lib/{}/libgcc_s.so.1',
    'lib/{}/libm.so.6',
    'usr/bin/patchelf',
    'usr/lib/{}/libstdc++.so.6',
  ))

install_app_runner = lambda app: \
  write_bash_script(get_app_runner_path(app), r'''
  declare -r app_path=''' + build_app_runner_relative_path(app, get_app_path(app)) + r'''
  declare -r browser_path=''' + build_app_runner_relative_path(app, install_app_browser(app)) + r'''
  declare -r cache_path=${XDG_CACHE_HOME-~/.cache}/''' + quote_argument(os.path.relpath(get_cache_path(), get_xdg_cache_path())) + r'''
  declare -r distribution_path=''' + build_app_runner_relative_path(app, get_app_distribution_path(app)) + r'''
  declare -r executable_arguments=(''' + normalize_app_command(app, sanitize_command(query_appfile(app, 'executable'))) + r''')
  declare -r firejail_options=(''' + sanitize_command(query_appfile(app, 'firejail')) + r''')
  declare -r firejail_options_path=''' + build_app_runner_relative_path(app, get_app_firejail_options_path(app)) + r'''
  declare -r root_path=''' + build_app_runner_relative_path(app, get_app_root_path(app)) + r'''
  declare -r urls_path=''' + build_app_runner_relative_path(app, os.path.join(get_app_path(app), 'urls')) + r'''

  # shellcheck disable=SC2088
  declare -r firejail_blacklisted_paths=(
    ''' + '\n    '.join(quote_argument(path) for path in get_firejail_blacklisted_paths()) + r'''
  )

  function build_directory_list {
    declare -n result_directory_list=$1
    shift

    declare directory_paths=()
    declare path
    for path; do
      [[ ! -d $path ]] || directory_paths+=("$path")
    done
    readonly directory_paths

    if [[ ${directory_paths-} ]]; then
      declare -r ifs=$IFS
      IFS=:
      result_directory_list=${directory_paths[*]}
      IFS=$ifs
    fi

    readonly result_directory_list
  }

  function build_environment {
    declare -n result_environment=$1
    shift

    result_environment=()

    result_environment[PATH]=$root_path/usr/bin:$root_path/bin:$PATH
    result_environment[PYTHONHOME]=$root_path/usr

    [[ ${executable_path-} ]] || get_executable_path executable_path
    [[ ${executable_path-} != ./AppRun ]] || result_environment[APPDIR]=$distribution_path

    build_gdk_pixbuf_path gdk_pixbuf_path
    [[ ! ${gdk_pixbuf_path-} ]] || result_environment[GDK_PIXBUF_MODULE_FILE]=$gdk_pixbuf_path

    build_directory_list python_path "$distribution_path"/usr/lib/python*/dist-packages "$root_path"/usr/lib/python*{,/dist-packages,/plat-*}
    [[ ! ${python_path-} ]] || result_environment[PYTHONPATH]=${PYTHONPATH+$PYTHONPATH:}$python_path

    if type firejail &> /dev/null; then
      result_environment[BROWSER]=$browser_path
      result_environment[TUXAPP_URLS]=$urls_path
    fi

    readonly result_environment
  }

  function build_firejail_arguments {
    declare -n result_firejail_arguments=$1
    declare -n argument_environment=$2
    shift 2

    result_firejail_arguments=(firejail --protocol="unix,inet,inet6,netlink")

    [[ ! ${TUXAPP_TRACE-} ]] || result_firejail_arguments+=(--allow-debuggers)

    declare name
    for name in "${!argument_environment[@]}"; do
      result_firejail_arguments+=(--env="$name=${argument_environment[$name]}")
    done

    declare path
    for path in "${firejail_blacklisted_paths[@]}"; do
      [[ ! -e ${path/#~/$HOME} ]] || result_firejail_arguments+=(--blacklist="$path")
    done

    result_firejail_arguments+=(--read-only="$root_path")

    declare path
    for path in "$cache_path" "${app_path%/*}"/*; do
      [[ ! -d $path || $path == "$app_path" ]] || result_firejail_arguments+=(--read-only="$path")
    done

    [[ ${executable_path-} ]] || get_executable_path executable_path
    if [[ ${executable_path-} ]]; then
      declare -r profile_path=/etc/firejail/${executable_path##*/}.profile
      if [[ -f $profile_path ]]; then
        declare profile
        profile=$(< "$profile_path")
        if [[ $profile =~ include\ ([^$'\n']) ]]; then
          declare -r included_path=/etc/firejail/${BASH_REMATCH[1]}.profile
          [[ ! -f $included_path ]] || profile=$(< "$included_path")
        fi
        readonly profile

        [[ $profile != *whitelist\ * ]] || result_firejail_arguments+=(--whitelist={"$distribution_path","$root_path"})
      fi
    fi

    declare app_firejail_options
    read_firejail_options app_firejail_options

    result_firejail_arguments+=(${firejail_options+"${firejail_options[@]}"} ${app_firejail_options+"${app_firejail_options[@]}"})

    readonly result_firejail_arguments
  }

  function build_gdk_pixbuf_path {
    declare -n result_gdk_pixbuf_path=$1
    shift

    declare path
    for path in "$root_path"/usr/lib/*-linux-gnu/gdk-pixbuf-2.0/*; do
      if [[ -d $path ]]; then
        result_gdk_pixbuf_path=$path/loaders.cache
        [[ -f $result_gdk_pixbuf_path ]] || "${path%/*}"/gdk-pixbuf-query-loaders "$path"/loaders/* > "$result_gdk_pixbuf_path"
        break
      fi
    done

    readonly result_gdk_pixbuf_path
  }

  function build_strace_arguments {
    declare -n result_strace_arguments=$1
    shift

    result_strace_arguments=()
    [[ ! ${TUXAPP_TRACE-} ]] || result_strace_arguments+=(strace -f -e open,openat,stat)
    readonly result_strace_arguments
  }

  function check_firejail {
    if type firejail &> /dev/null; then
      declare app_firejail_options
      read_firejail_options app_firejail_options

      [[ ${WAYLAND_DISPLAY-} || " ${firejail_options[@]} ${app_firejail_options[@]} " == " --x11[ =]" ]] || echo ''' + quote_argument(get_firejail_message('x11')) + r''' >&2
      [[ ! ${firejail_options-} ]] || echo ''' + quote_argument(get_firejail_message('options')).format('\'"${firejail_options[*]}"\'') + r''' >&2
    else
      [[ ${TUXAPP_TEST-} ]] || echo ''' + quote_argument(get_firejail_message('missing')) + r''' >&2
    fi
  }

  function get_executable_path {
    declare -n result_executable_path=$1
    shift

    declare argument
    for argument in "${executable_arguments[@]}"; do
      if [[ $argument == ./* ]]; then
        result_executable_path=$argument
        break
      fi
    done

    readonly result_executable_path
  }

  function listen_urls {
    [[ -f $urls_path ]] || touch "$urls_path"
    while read -r; do
      setsid xdg-open "$REPLY" &
    done < <(tail -f -n 0 --pid=$$ "$urls_path" 2> /dev/null) &
  }

  function main {
    check_firejail

    declare -A environment
    build_environment environment

    if type firejail &> /dev/null; then
      listen_urls

      declare firejail_arguments
      build_firejail_arguments firejail_arguments environment
    else
      declare name
      for name in "${!environment[@]}"; do
        export "$name=${environment[$name]}"
      done
    fi

    declare strace_arguments
    build_strace_arguments strace_arguments

    # shellcheck disable=SC2086
    exec ${firejail_arguments+"${firejail_arguments[@]}"} ${strace_arguments+"${strace_arguments[@]}"} ${executable_arguments+"${executable_arguments[@]/.\//"$distribution_path"/}"} "$@"
  }

  function read_firejail_options {
    declare -n result_firejail_options=$1
    shift

    result_firejail_options=()
    [[ ! -f $firejail_options_path ]] || eval "result_firejail_options=($(< "$firejail_options_path"))"
    readonly result_firejail_options
  }

  main "$@"
  ''')

is_app_installed = lambda app: \
  os.path.isfile(get_app_version_path(app)) and \
  os.path.isdir(get_app_distribution_path(app))

is_app_updated = lambda app: \
  is_app_installed(app) and \
  read_app_version(app) == request_app_version_cached(app)

is_debian_repository = lambda repository: \
  repository in (
    'jessie',
    'stretch',
  )

is_file_executable = lambda path: \
  os.path.isfile(path) and \
  os.access(path, os.X_OK) and \
  not is_file_library(path)

is_file_library = lambda path: \
  os.path.isfile(path) and \
  (os.path.splitext(path)[1] in ('.node', '.so') or '.so.' in path)

is_file_list_nested = lambda paths: all(path.lstrip('./').split('/', 1)[0] == paths[0].lstrip('./').split('/', 1)[0] for path in paths)

is_file_magic_number = lambda path, magic_number: read_file_binary(path, len(magic_number)) == magic_number

is_file_newer = lambda path, reference_path: get_file_mtime(path) > get_file_mtime(reference_path)

is_library_package_ignored = lambda package: \
  re.match(r'libx?32', package) or \
  re.search(r'-(cross|dbg|dev|i386|x32)$', package)

is_package_library = lambda package: \
  package.startswith('lib') or \
  package == 'zlib1g'

is_silent = lambda: getattr(silence, 'is_silent', False)

is_tarball_nested = lambda path: is_file_list_nested(read_process(('tar', '-t', '-f', path)).splitlines())

is_zip_file_nested = lambda path: is_file_list_nested(zipfile.ZipFile(path).namelist())

join_arguments = lambda arguments: ' '.join(quote_argument(argument) for argument in arguments)

list_all_apps = \
  output(lambda *args, **kwargs: '\n'.join(kwargs['result']))(
    lambda: tuple(request_grep_url(build_github_api_url('repos/{}/contents/apps'.format(get_github_repository())), ('-Po', r'(?<="name": ")(?!\.)[^"]+')).splitlines())
  )

list_app_distribution = lambda app: (path for path in list_directory(get_app_distribution_path(app)) if '/node_modules/' not in path)

list_directory = lambda path: (os.path.join(path, filename) for path, directories, filenames in os.walk(path) for filename in filenames)

list_directory_elf_files = lambda path: tuple(path for path in list_directory(path) if (is_file_executable(path) or is_file_library(path) and '/gconv/' not in path and not os.path.basename(path).startswith('ld-')) and not os.path.islink(path) and is_file_magic_number(path, b'\x7fELF'))

list_installed_apps = \
  output(lambda *args, **kwargs: '\n'.join('{} {}'.format(app, version) for app, version in kwargs['result']))(
    lambda: tuple((app, read_app_version(app)) for app in get_installed_apps())
  )

main = \
  handle_exceptions(
  check('Exit with error')(
    lambda: \
      list_all_apps() \
        if parse_arguments().all else \
      check_apps_updated(check_app_installed(extract_app(argument)) for argument in parse_arguments().arguments or get_installed_apps()) \
        if parse_arguments().check else \
      execute_app(check_app_installed(extract_app(parse_arguments().arguments[0])), tuple(parse_arguments().arguments[1:])) \
        if parse_arguments().execute and parse_arguments().arguments else \
      list_installed_apps() \
        if parse_arguments().list else \
      purge_cache() \
        if parse_arguments().purge else \
      all(remove_app(check_app_installed(extract_app(argument), True)) for argument in parse_arguments().arguments) \
        if parse_arguments().remove else \
      all(install_app(check_app_installed(extract_app(argument))) for argument in parse_arguments().arguments or get_installed_apps()) \
        if parse_arguments().update else \
      all(install_app(extract_app(argument)) for argument in parse_arguments().arguments) \
        if parse_arguments().arguments else \
      parse_arguments(('-h',))
  ))

make_file_directories = lambda path: \
  make_directories(os.path.dirname(path)) and \
  path

move_directory = lambda path, destination_path: \
  copy_directory(path, destination_path) and \
  remove_directory_ascending(path) and \
  destination_path

normalize_app_command = lambda app, command: join_arguments(os.path.realpath(get_app_distribution_file_path(app, argument)).replace(get_app_distribution_path(app), '.', 1) if argument.startswith('./') else argument for argument in split_command(command))

parse_appfile = lambda app: dict(line.split('=', 1) for line in read_appfile(app).splitlines())

patch_app_elf_files = lambda app, path: \
  install_app_patchelf(app) and \
  patch_app_elf_files_patchelf(app, list_directory_elf_files(path))

patch_app_elf_files_patchelf = \
  log('Patching ELF files')(
  check('Failed to patch ELF files for {}')(
    lambda app, paths: \
      uncheck(call_process)(join_arguments(
        build_firejail_arguments() + \
        ('python', '-') + \
        (get_app_patchelf_path(app), join_arguments((get_app_dynamic_linker_path(app), '--library-path', get_app_patchelf_path(app), get_app_patchelf_file_path(app, 'patchelf'))), get_app_path(app), get_app_root_path(app), build_app_library_path(app), '1' if re.match(r'0\.8\b', read_app_package_version(app, 'patchelf')) else '', get_app_dynamic_linker_path(app)) + \
        paths,
      ) + ' << EOF' + textwrap.dedent(r'''
      from __future__ import print_function
      import os
      import stat
      import subprocess
      import sys
      try:
        from shlex import quote
      except ImportError:
        from pipes import quote
      patchelf_path, patchelf_command, app_path, root_path, library_path, is_old_patchelf, interpreter_path = sys.argv[1:8]
      for path in sys.argv[8:]:
        if os.path.dirname(path) != patchelf_path and (not path.startswith('{}/'.format(root_path)) or os.path.getatime(path) - os.path.getmtime(path) > 60 * 5):
          paths = tuple(path for path in subprocess.check_output('{} --print-rpath {} 2> /dev/null || :'.format(patchelf_command, quote(path)), shell=True).rstrip().split(':') if path)
          patched_paths = \
            tuple(os.path.join(root_path, path.lstrip('/')) if path.startswith('/') and not path.startswith(app_path) else path for path in paths) + \
            tuple(path for path in ('{}/'.format(os.path.join('\$ORIGIN', os.path.relpath(library_path, os.path.dirname(path)))) for library_path in library_path.split(':')) if path not in paths)
          if patched_paths != paths:
            if not os.access(path, os.W_OK):
              os.chmod(path, os.stat(path).st_mode | stat.S_IWUSR)
            output = subprocess.check_output('{} {}--force-rpath {}--set-rpath {} {} 2>&1 || :'.format(patchelf_command, '' if is_old_patchelf else '--no-default-lib ', '--set-interpreter {} '.format(quote(interpreter_path)) if os.access(path, os.X_OK) and os.path.splitext(path)[1] != '.so' and '.so.' not in path else '', quote(':'.join(patched_paths)), quote(path)), shell=True)
            if not all(line.startswith('warning: working around ') or line == 'cannot find section .interp' or is_old_patchelf and line == 'maximum file size exceeded' for line in output.splitlines()) and os.path.basename(path) != 'libwidevinecdm.so':
              print('Failed to patch {}'.format(path), file=sys.stderr)
              print(output, end='', file=sys.stderr)
              sys.exit(1)
      EOF
      '''))
  ))

patch_app_package = lambda app, package: \
  symlink_file(get_app_root_file_path(app, os.path.join('usr/lib', detect_library_directory_name(), 'libGL.so.1')), 'mesa/libGL.so.1') \
    if package == 'libgl1-mesa-glx' and not os.path.isfile(get_app_root_file_path(app, os.path.join('usr/lib', detect_library_directory_name(), 'libGL.so.1'))) else \
  all(write_file(os.path.join(path, 'qt.conf'), textwrap.dedent('''\
  [Paths]
  Data = ../../share/qt5
  LibraryExecutables = qt5/libexec
  Plugins = qt5/plugins
  Prefix = {}
  Translations = ../../share/qt5/translations
  ''').format(os.path.relpath(get_app_root_file_path(app, os.path.join('usr/lib', detect_library_directory_name())), path))) for path in (
    get_app_root_file_path(app, 'usr/bin'),
    get_app_root_file_path(app, os.path.join('usr/lib', detect_library_directory_name(), 'qt5/libexec')),
  )) \
    if package in ('python-pyqt5', 'python3-pyqt5') else \
  True

purge_cache = \
  log_after('Purged cache')(
    lambda: remove_directory(get_cache_path())
  )

query_app_package_data = lambda app, key: query_data(get_app_package_data_path(app), key)

query_app_package_data_lock = lambda app: int(query_app_package_data(app, 'lock') or '0')

query_app_package_url = \
  check('Unknown package: {1}')(
    lambda app, package: query_app_package_data(app, (package, 'url'))
  )

query_appfile = lambda app, key: \
  query_appfile_download_urls(app) \
    if key == 'download-urls' else \
  tuple(query_appfile_value(app, 'ignored-libraries').split()) \
    if key == 'ignored-libraries' else \
  expand_package_groups(query_appfile_value(app, 'packages').split()) \
    if key == 'packages' else \
  query_appfile_value(app, key).lstrip('~') \
    if key in ('description', 'name', 'title') else \
  query_appfile_value(app, key)

query_appfile_download_urls = \
  check('No download URL of {} for your architecture')(
    lambda app: tuple(filter_app_download_url(app, url) for url in (uncheck(query_appfile_value)(app, 'download-{}-url'.format(detect_architecture())) or '').split())
  )

query_appfile_value = \
  check(lambda app, key, *args, **kwargs: kwargs['result'] is None and 'Failed to get {}.{}'.format(app, key))(
    lambda app, key: parse_appfile(app).get(key)
  )

query_data = lambda path, key: (connect_data(path).execute('SELECT value FROM items WHERE key = ?', (build_data_key(key),)).fetchone() or ('',))[0]

query_package_data_header = lambda path, key: parse_package_data_header(path).get(key)

read_app_download_urls_hash = lambda app: read_app_version_components(app)[-1]

read_app_firejail_options = lambda app: read_file(get_app_firejail_options_path(app)).rstrip()

read_app_lock = lambda app: int(read_file(get_app_lock_path(app)) or '0')

read_app_package_version = lambda app, package: read_file(get_app_package_version_path(app, package)).rstrip()

read_app_version = lambda app: read_app_version_components(app)[0]

read_app_version_components = lambda app: tuple(read_file(get_app_version_path(app)).rstrip().rsplit(None, 1)) or ('',)

read_appfile = lambda app: \
  read_file(get_appfile_path(app)) or \
  request_appfile(app)

read_file_binary = lambda path, size=-1: read_file(path, size, True)

read_process = lambda arguments, is_stderr_redirected=False: read_process_binary(arguments, is_stderr_redirected).decode('utf-8', 'replace')

remove_app = \
  lock_app(
  log_after('Removed {}')(
    lambda app: \
      remove_directory(get_app_path(app)) and \
      remove_file(get_app_desktop_entry_path(app)) and \
      True
  ))

remove_directory_ascending = lambda path: \
  remove_directory(path) and \
  remove_empty_directories(os.path.dirname(path))

remove_file_ascending = lambda path: \
  remove_file(path) and \
  remove_empty_directories(os.path.dirname(path))

remove_old_files = lambda pattern, days=30: all(remove_file(path) for path in glob.iglob(pattern) if os.path.getatime(path) < time.time() - 60 * 60 * 24 * days)

rename_file_ascending = lambda path, destination_path: \
  rename_file(path, destination_path) and \
  remove_empty_directories(os.path.dirname(path)) and \
  destination_path

request_app_library_packages = lambda app, libraries: \
  tuple(unquote_url(line) for lines in (request_grep_urls(tuple('https://{}/search?{}'.format('packages.debian.org' if is_debian_repository(query_appfile(app, 'package-repository')) else 'packages.ubuntu.com', encode_url_parameters({
    'arch': detect_debian_architecture(),
    'keywords': library,
    'mode': 'exactfilename',
    'searchon': 'contents',
    'suite': query_appfile(app, 'package-repository'),
  })) for library in libraries if not query_app_package_data(app, (library, 'package'))), ('-Po', r' [^\s]+(?=</title>)|(?<="/{}/)[^"]+'.format(re.escape(query_appfile(app, 'package-repository'))))) for libraries in (libraries[index:index + get_app_library_packages_request_size()] for index in range(0, len(libraries), get_app_library_packages_request_size()))) for line in lines)

request_app_version = lambda app, pattern=None: request_app_version_memoized(app, query_appfile(app, 'version-url'), pattern or query_appfile(app, 'version-regex'))

request_app_version_cached = lambda app, pattern=None: \
  read_app_version(app) \
    if get_file_mtime(get_app_version_path(app)) > time.time() - 60 * 5 else \
  touch_file(get_app_version_path(app)) and \
  read_app_version(app) \
    if request_app_version(app) == read_app_version(app) else \
  request_app_version(app)

request_app_version_memoized = \
  memoize_temporarily(
  log(lambda app, url, *args, **kwargs: 'Requesting the version number of {} on {}'.format(app, url))(
  check(lambda app, url, *args, **kwargs: 'Failed to request the version number of {} on {}'.format(app, url))(
    lambda app, url, pattern: search(pattern, silence(request_grep_url_all)(url, ('-Pao', '-m', '1', '--', pattern)).splitlines()[0], 0, 1).strip().replace(os.path.sep, '-')
  )))

request_appfile = \
  memoize_temporarily(
  check('{} was not found')(
    lambda app: uncheck(request_url)(build_github_raw_url('apps/{}'.format(app)))
  ))

request_grep_url = \
  log('Requesting {}')(
  check('Failed to request and grep {}')(
    lambda url, arguments: \
      uncheck(read_process)(r'{} | {} | {} | grep {} 2> /dev/null || :'.format(join_arguments(build_request_arguments(
        ('-Ss', url),
        ('-q', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command(), join_arguments(arguments))).rstrip('\n')
  ))

request_grep_url_all = \
  log('Requesting {}')(
  check('Failed to request and grep {}')(
    lambda url, arguments: \
      uncheck(read_process)(r'( {} | {} ) 2>&1 | {} | grep {} 2> /dev/null || :'.format(join_arguments(build_request_arguments(
        ('-Ss', '-D', '/dev/stderr', url),
        ('-Sq', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command(), join_arguments(arguments))).rstrip('\n')
  ))

request_grep_urls = \
  check(lambda urls, *args, **kwargs: kwargs['result'] is None and 'Failed to request and grep URLs')(
    lambda urls, arguments: \
      tuple((uncheck(read_process)(r'{} | {} | {} | grep {} 2> /dev/null || :'.format(join_arguments(build_request_arguments(
        ('-Ss',) + urls,
        ('-q', '-O', '-',) + urls,
      True)), get_request_gzip_command(), get_request_head_command(), join_arguments(arguments))) or '').splitlines()) or \
      None \
        if urls else \
      ()
  )

request_url = \
  log('Requesting {}')(
  check('Failed to request {}')(
    lambda url: \
      uncheck(read_process)(r'{} | {} | {}'.format(join_arguments(build_request_arguments(
        ('-Ss', url),
        ('-q', '-O', '-', url),
      True)), get_request_gzip_command(), get_request_head_command()))
  ))

request_url_headers = \
  log('Requesting {}')(
  check('Failed to request {}')(
    lambda url: \
      uncheck(read_process)(build_request_arguments(
        ('-ISs', '-X', 'GET', url),
        ('-Sq', '-O', '-', '--spider', url),
      ), get_request_command() == 'wget')
  ))

resolve_app_packages = lambda app, packages: tuple(sorted(set(extract_package_name(query_app_package_url(app, package)) for package in resolve_app_packages_recursive(app, packages))))

resolve_app_packages_recursive = lambda app, packages, resolved_packages=set(): \
  functools.reduce(lambda packages, package: \
    packages | \
    {package} | \
    resolve_app_packages_recursive(app, tuple(dependency for dependency in query_app_package_data(app, (package, 'dependencies')).split() if (is_package_library(dependency) or not package.startswith('lib')) and dependency not in resolved_packages), # pylint: disable=undefined-variable
  packages | {package}), packages, set())

resolve_outdated_app_packages = lambda app, packages: tuple(package for package in resolve_app_packages(app, packages) if not extract_package_version(parse_url(query_app_package_url(app, package)).path) == read_app_package_version(app, package))

sanitize_command = lambda command: join_arguments(split_command(command))

search = lambda pattern, string, flags=0, group=0: getattr(re.search(pattern, string, flags), 'group', lambda *args, **kwargs: '')(group)

unpack_app_appimage1_distribution = \
  log(lambda app, path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda app, path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      install_app_packages(app, ('libarchive-tools', 'liblzo2-2')) and \
      uncheck(call_process)(
        build_firejail_arguments() + \
        (get_app_root_binary_path(app, 'bsdtar'), '-x', '-C', make_directories(get_app_distribution_path(app)), '-f', path)
      ) and \
      get_app_distribution_path(app)
  ))

unpack_app_appimage2_distribution = \
  log(lambda app, path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda app, path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      uncheck(call_process)('cd {} && {} 2> /dev/null'.format(quote_argument(make_directories(get_app_path(app))), join_arguments(
        build_firejail_arguments() + \
        (change_file_mode(path, lambda mode: mode | stat.S_IXUSR), '--appimage-extract')
      ))) and \
      move_directory(os.path.join(get_app_path(app), 'squashfs-root'), get_app_distribution_path(app))
  ))

unpack_app_distribution = \
  check(lambda app, path, *args, **kwargs: 'Unknown file format of {}'.format(os.path.basename(path)))(
    lambda app, path: \
      unpack_app_appimage1_distribution(app, path) \
        if is_file_magic_number(path, b'\x7fELF\x02\x01\x01\x00AI\x01') else \
      unpack_app_appimage2_distribution(app, path) \
        if is_file_magic_number(path, b'\x7fELF\x02\x01\x01\x00AI\x02') else \
      unpack_app_package_distribution(app, path) \
        if is_file_magic_number(path, b'!<arch>\n') else \
      unpack_app_zip_distribution(app, path) \
        if is_file_magic_number(path, b'PK') else \
      unpack_app_tarball_distribution(app, path)
        if is_file_magic_number(path, b'\x1f\x8b') or is_file_magic_number(path, b'\xfd7zXZ\x00\x00') or is_file_magic_number(path, b'BZh') else \
      None
  )

unpack_app_package_distribution = lambda app, path: \
  unpack_package(path, get_app_distribution_path(app)) and \
  all(symlink_file(path, os.path.relpath(get_app_distribution_file_path(app, os.readlink(path).lstrip('/')), os.path.dirname(path))) for path in glob.iglob(get_app_distribution_binary_path(app, '*')) if os.path.islink(path) and os.readlink(path).startswith('/')) and \
  get_app_distribution_path(app)

unpack_app_tarball_distribution = \
  log(lambda app, path, *args, **kwargs: 'Preparing to unpack {}'.format(os.path.basename(path)))(
    lambda app, path: \
      unpack_tarball(path, get_app_distribution_path(app), ('--strip-components=1',) if is_tarball_nested(path) else ()) and \
      unpack_nested_app_distributions(app)
  )

unpack_app_zip_distribution = lambda app, path: \
  (move_directory(next(glob.iglob(os.path.join(unpack_zip_file(path, os.path.join(get_app_path(app), 'unpack')), '*'))), get_app_distribution_path(app)) if is_zip_file_nested(path) else unpack_zip_file(path, get_app_distribution_path(app))) and \
  unpack_nested_app_distributions(app)

unpack_nested_app_distributions = lambda app: \
  all(unpack_app_distribution(app, path) and remove_file_ascending(path) for path in list_app_distribution(app) if os.path.splitext(path)[1].lower() in ('.appimage', '.deb')) and \
  get_app_distribution_path(app)

unpack_package = \
  log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
  output(' ')(
    lambda path, output_path, options=(): \
      uncheck(pipe_process_stdin)(open(path, 'rb'),
        ('tar', '-x', get_tar_filter_option(query_package_data_header(path, 'extension')), '-C', make_directories(output_path)) + \
        get_tar_progress_options() + \
        options,
      query_package_data_header(path, 'offset'), query_package_data_header(path, 'size')) and \
      output_path
  )))

unpack_tarball = \
  log(lambda path, *args, **kwargs: 'Unpacking {}'.format(os.path.basename(path)))(
  check(lambda path, *args, **kwargs: 'Failed to unpack {}'.format(os.path.basename(path)))(
  output(' ')(
    lambda path, output_path, options=(): \
      uncheck(call_process)(
        ('tar', '-x', '-C', make_directories(output_path), '-f', path) + \
        get_tar_progress_options() + \
        options
      ) and \
      output_path
  )))

update_app_package_data = lambda app, key, value='', is_deferred=False: update_data(get_app_package_data_path(app), key, value, is_deferred)

update_app_package_data_items = lambda app, items, is_deferred=False: update_data_items(get_app_package_data_path(app), items, is_deferred)

update_app_package_data_list_items = lambda app, items: \
  (not any('Provides' in item for item in items) or update_app_package_data_list_items(app, tuple(dict(((key, value) for key, value in item.items() if key != 'Provides'), **{'Package': package}) for item in items if 'Provides' in item for package in item['Provides'].split()))) and \
  update_app_package_data_items(app, (((item['Package'], 'dependencies'), ' '.join(item[key] for key in ('Depends', 'Pre-Depends') if item.get(key))) for item in items), True) and \
  update_app_package_data_items(app, (((item['Package'], 'url'), item['Filename']) for item in items), True)

update_app_package_list = \
  log('Updating the package data from {1}')(
  check('Failed to update the package data from {1}')(
    lambda app, url, path: \
      functools.reduce(lambda items, line: \
        # pylint: disable=undefined-variable
        update_app_package_data_list_items(app, items[:-1]) and \
        ({},) \
          if line == 'EOF' else \
        items[:-1] + (dict(items[-1], **dict((line.split(': ', 1),))),) \
          if line else \
        items + ({},) \
          if len(items) < 100 else \
        update_app_package_data_list_items(app, items) and \
        ({},),
      uncheck(read_process_lines)(r'''
      xzgrep '^\($\|\(Depends\|Filename\|Package\|Pre-Depends\|Provides\): \)' {} | \
      sed 's/ ([^)]\+)//g; s/ | [^,]\+//g; s/:any//g; s/, / /g; s|^Filename: |\0{}/|' 2> /dev/null
      echo EOF
      '''.format(
        quote_argument(path),
        quote_argument('/'.join(url.split('/', 4)[:-1])),
      )), ({},)) and \
      commit_data(get_app_package_data_path(app)) and \
      remove_file(path)
  ))

update_app_package_lists = \
  lock_app_package_data(
    lambda app: all(update_updated_app_package_list(app, url) for url in build_app_package_list_urls(app))
  )

update_data = lambda path, key, value='', is_deferred=False: \
  connect_data(path).execute('REPLACE INTO items (key, value) VALUES (?, ?)', (build_data_key(key), value)) and \
  (is_deferred or commit_data(path))

update_data_items = lambda path, items, is_deferred=False: \
  connect_data(path).executemany('REPLACE INTO items (key, value) VALUES (?, ?)', ((build_data_key(key), value) for key, value in items)) and \
  (is_deferred or commit_data(path))

update_updated_app_package_list = lambda app, url: \
  int(query_app_package_data(app, ('timestamp', hash_md5(url))) or '0') > time.time() - 60 * 60 * 24 or \
  (request_url_timestamp(url) <= int(query_app_package_data(app, ('timestamp', hash_md5(url))) or '0') or update_app_package_list(app, url, download_missing_app_temp_file(app, url))) and \
  update_app_package_data(app, ('timestamp', hash_md5(url)), int(time.time()))

write_app_package_file_version = lambda app, path: write_file(get_app_package_version_path(app, extract_package_name(path)), '{}\n'.format(extract_package_version(path)))

write_app_version = lambda app: write_file(get_app_version_path(app), '{} {}\n'.format(request_app_version(app), hash_app_download_urls(app)))

write_bash_script = lambda path, content: \
  write_executable_file(path, textwrap.dedent('''\
  #!/usr/bin/env bash
  set -eu -o pipefail
  ''') + textwrap.dedent(content))

write_executable_file = lambda path, content: change_file_mode(write_file(path, content), lambda mode: mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

if __name__ == '__main__':
  main()
